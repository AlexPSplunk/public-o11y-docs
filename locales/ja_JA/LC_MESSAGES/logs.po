# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023 Splunk, Inc
# This file is distributed under the same license as the Splunk package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2023.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Splunk \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-08-01 01:26+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: ja_JA\n"
"Language-Team: ja_JA <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.10.3\n"

#: ../../logs/LOconnect-scenario.rst:-1
msgid ""
"Aisha troubleshoots problems in a workflow using Log Observer where Log "
"Observer accesses Splunk platform logs through Log Observer Connect."
msgstr ""

#: ../../<rst_prolog>:18
msgid "Take shift"
msgstr ""

#: ../../logs/LOconnect-scenario.rst:5
msgid "Scenario: Aisha troubleshoots workflow failures with Log Observer"
msgstr ""

#: ../../logs/LOconnect-scenario.rst:11
msgid ""
"Buttercup Games, a fictitious company, runs an e-commerce site to sell "
"its products. They analyze logs in Splunk Cloud Platform. They recently "
"refactored their site to use a cloud-native approach with a microservices"
" architecture and Kubernetes for the infrastructure. They purchased "
"Splunk Observability Cloud as their observability solution. Buttercup "
"Games analyzes their Splunk Cloud Platform logs in Log Observer, a point-"
"and-click Splunk Observability Cloud tool, which they set up through Log "
"Observer Connect."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:13
msgid ""
"Buttercup Games site reliability engineers and service owners collaborate"
" to monitor and maintain the site to ensure that people have a great "
"experience when they visit. They use Splunk Observability Cloud to find "
"and solve problems that cause outages or failures in purchases from their"
" online store."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:15
msgid ""
"In the past hour, the number of purchases on the Buttercup Games site "
"dropped significantly and the checkout completion rate is too low. Aisha,"
" an SRE, and Deepu, a service owner, perform the following tasks with "
"Splunk Log Observer and other views in Splunk Observability Cloud to "
"identify and troubleshoot the root cause of the problem with the purchase"
" workflow:"
msgstr ""

#: ../../logs/LOconnect-scenario.rst:17
msgid ":ref:`which-logs-matter`"
msgstr ""

#: ../../logs/LOconnect-scenario.rst:19
msgid ":ref:`conduct-initial-analysis`"
msgstr ""

#: ../../logs/LOconnect-scenario.rst:21
msgid ":ref:`find-log-patterns`"
msgstr ""

#: ../../logs/LOconnect-scenario.rst:23
msgid ":ref:`narrow-hypothesis`"
msgstr ""

#: ../../logs/LOconnect-scenario.rst:25
msgid ":ref:`test-hypothesis`"
msgstr ""

#: ../../logs/LOconnect-scenario.rst:27
msgid ":ref:`identify-and-remediate`"
msgstr ""

#: ../../logs/LOconnect-scenario.rst:33
msgid "Determine which logs matter"
msgstr ""

#: ../../logs/LOconnect-scenario.rst:34
msgid ""
"Aisha opens the service map in Splunk Application Performance Monitoring "
"(APM). To find out why the checkout completion rate is so low, they "
"select the :strong:`/cart/checkout` business workflow on the service map."
" The service map now shows Aisha the dependency interactions among the "
"full set of services backing the :strong:`/cart/checkout` workflow."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:36
msgid ""
"This screenshot shows a service map in Splunk APM displaying the "
"paymentservice as the source of root errors."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:41
msgid ""
"Aisha sees that :strong:`paymentservice` has the highest number of "
"downstream errors that are contributing to a degraded experience for the "
"workflow. Splunk APM identifies the issues as root cause errors. Aisha "
"selects :strong:`paymentservice`. Splunk Observability Cloud displays "
"details about the service’s errors and latency."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:43
msgid ""
"Splunk Observability Cloud also surfaces Related Content tiles that "
"provide access to relevant data in other areas of the application. For "
"example, Aisha can look at the health of the Kubernetes cluster where "
":strong:`paymentservice` is running or they can examine logs being issued"
" by the :strong:`paymentservice`."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:45
msgid ""
"This screenshot shows a service map in Splunk APM providing access to two"
" Related Content tiles: K8s clusters for paymentservice and Logs for "
"paymentservice."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:49
msgid ""
"Aisha decides to look at the log details. They select the Related Content"
" tile, :strong:`Logs for paymentservice`. Log Observer opens, and Aisha’s"
" view is automatically narrowed to display only logs from "
":strong:`paymentservice`. Log Observer displays :strong:`paymentservice` "
"logs that were sent in to Splunk Cloud Platform. Log Observer does not "
"ingest the logs, but displays the logs from their storage in Splunk Cloud"
" Platform."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:51
msgid ""
"Because Aisha first tracked the workflow problems in Splunk APM, they "
"were able to narrow their search down to only logs coming from "
":strong:`paymentservice`. Now Aisha can use Log Observer to analyze the "
"logs."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:57
msgid "Conduct initial analysis of logs"
msgstr ""

#: ../../logs/LOconnect-scenario.rst:58
msgid ""
"Aisha can query the :strong:`paymentservice` logs in Log Observer's "
"point-and-click UI, then filter and aggregate the logs to drill down to "
"the underlying problem. For more complex analysis using SPL query "
"language, they can continue their analysis of :strong:`paymentservice` "
"logs in the Splunk Cloud Platform Search & Reporting application."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:60
msgid ""
"Looking through the incoming logs in the logs table, Aisha sees some "
"error logs, so they select one to see more details in a structured view. "
"In the log details view on the right, Aisha notices the error message: "
"``Failed payment processing through ButtercupPayments: Invalid API Token "
"(test-20e26e90-356b-432e-a2c6-956fc03f5609)``."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:62
msgid ""
"This screenshot shows the details of an error log in Splunk Log Observer,"
" including the error severity and an error message."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:66
msgid ""
"Aisha decides to see if other logs have the same error message. If they "
"can find a pattern, they can figure out what is causing the trouble."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:72
msgid "Find log patterns"
msgstr ""

#: ../../logs/LOconnect-scenario.rst:73
msgid ""
"Aisha opens a few other logs to see if others have the same error "
"message. Several of the logs Aisha opens have the same error message: "
"``Failed payment processing through ButtercupPayments: Invalid API Token "
"(test-20e26e90-356b-432e-a2c6-956fc03f5609)``."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:75
msgid ""
"Aisha notes that all of the invalid API tokens start with “test”. Aisha "
"hypothesizes that a team pushed the current version, v350.10, live with a"
" test token that doesn’t work in production."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:77
msgid ""
"To double-check their hypothesis, Aisha selects the error message and "
"selects :strong:`Add to filter` to show only the logs that contain the "
"same error message."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:83
msgid "Narrow the hypothesis"
msgstr ""

#: ../../logs/LOconnect-scenario.rst:84
msgid ""
"Next, Aisha wants to group the logs by version to see if the group of "
"logs that contain the test API token are on multiple versions. They "
"change the :strong:`Group by` field to :strong:`version`."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:86
msgid ""
"Now Aisha can see that all logs that contain the test API token are on "
"version v350.10."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:88
msgid ""
"This screenshot shows the Log Observer page with events filtered down by "
"the error message and grouped by a version of version 350.10. All of the "
"logs that display are error logs."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:92
msgid ""
"Aisha is pretty confident that they have isolated the problem to logs "
"containing the error message: ``Failed payment processing through "
"ButtercupPayments: Invalid API Token (test-20e26e90-356b-432e-"
"a2c6-956fc03f5609)`` in only the most recent version, v350.1. Now they "
"want to test their hypothesis."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:98
msgid "Test the hypothesis"
msgstr ""

#: ../../logs/LOconnect-scenario.rst:99
msgid ""
"To be sure, Aisha selects the eye icon for the message filter value to "
"temporarily exclude the filter. Now there are logs that show up for "
"version v350.9 too, but they don’t include the error message. Aisha can "
"now correlate all of the logs containing the test token error message, "
"and no logs that don't contain the error message, to version v350.10."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:105
msgid "Identify the root cause and remediate"
msgstr ""

#: ../../logs/LOconnect-scenario.rst:106
msgid ""
"Their exploration in Log Observer convinces Aisha that the test API token"
" in v350.10 is the most likely source of the failures to complete "
"payment. Aisha rolls back the Buttercup Games code from the problematic "
"v350.10 to v350.9."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:108
msgid ""
"Aisha notifies Deepu about the invalid API token, which is a test token. "
"Deepu replaces the test token with a token that works in production."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:112
msgid "Summary"
msgstr ""

#: ../../logs/LOconnect-scenario.rst:113
msgid ""
"When Buttercup Games' e-commerce site began having a slow checkout "
"completion rate and saw a drop in the number of purchases, a site "
"reliability engineer, Aisha, looked at the :strong:`/cart/checkout` "
"business workflow on the Splunk APM service map. They saw that APM "
"identified the :strong:`paymentservice` as the root cause of errors. "
"Aisha decided to look into the log details by linking from APM to related"
" logs through the Related Content bar."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:115
msgid ""
"In Log Observer, Aisha noticed that several logs coming from "
":strong:`paymentservice` had the same error. The common error messages "
"indicated that the API token started with “test”. They figured that the "
"test token was the problem. They ruled out other possible problems by "
"filtering and aggregating logs. They correlated the suspicious test token"
" error message with only logs in v350.10."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:117
msgid ""
"Consulting with Deepu, the :strong:`paymentservice` owner, they agreed "
"that the test API token was the likely cause of the problem. Aisha rolled"
" back the code to the previous version because v350.9 logs did not "
"contain the test token error message. Then Deepu replaced the test token "
"with a token that works in production."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:119
msgid ""
"After the fix, users were able to complete checkout and make purchases "
"from the Buttercup Games e-commerce site. To prevent similar problems in "
"the future, Aisha decided to create a detector to alert their team when "
"tokens contain \"test\". The alert and detector will notify Aisha's and "
"Deepu's teams before customers attempt to make purchases that will fail."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:123
msgid "Learn more"
msgstr ""

#: ../../logs/LOconnect-scenario.rst:125
msgid "For details on business workflows, see :ref:`apm-workflows`."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:127
msgid ""
"For details on using Related Content, see :ref:`get-started-"
"relatedcontent`."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:129
msgid "For details on Log Observer queries, see :ref:`logs-queries`."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:131
msgid "For details on aggregating logs, see :ref:`logs-aggregations`."
msgstr ""

#: ../../logs/LOconnect-scenario.rst:133
msgid "For details on alerts and detectors, see :ref:`create-detectors`."
msgstr ""

#: ../../logs/LOconnect-troubleshoot.rst:-1 ../../logs/lo-connect-limits.rst:-1
msgid ""
"See Log Observer Connect’s limits on MB of data ingested or indexed per "
"month, limits on the number and type of processing rules, and search "
"query limits."
msgstr ""

#: ../../logs/LOconnect-troubleshoot.rst:5
msgid "Troubleshoot Log Observer Connect setup"
msgstr ""

#: ../../logs/LOconnect-troubleshoot.rst:11
msgid ""
"This topic helps Log Observer Connect administrators and users resolve "
"issues that might arise when searching Splunk platform indexes in Log "
"Observer Connect."
msgstr ""

#: ../../logs/LOconnect-troubleshoot.rst:14
msgid "Log Observer Connect users see unauthorized Splunk platform indexes"
msgstr ""

#: ../../logs/LOconnect-troubleshoot.rst:15
msgid ""
"When searching in Log Observer Connect, users might see Splunk Enterprise"
" or Splunk Cloud Platform indexes that are unauthorized for Log Observer "
"Connect users."
msgstr ""

#: ../../logs/LOconnect-troubleshoot.rst:18
msgid "Cause"
msgstr ""

#: ../../logs/LOconnect-troubleshoot.rst:19
msgid ""
"All Splunk Enterprise and Splunk Cloud Platform users can list all "
"indexes by default. However, if the ``indexes_list_all`` capability is "
"enabled in ``authorize.conf``, access to all indexes is limited to only "
"those roles with this capability."
msgstr ""

#: ../../logs/LOconnect-troubleshoot.rst:21
msgid ""
"If Log Observer Connect users see an index in Log Observer Connect that "
"is not authorized for Log Observer Connect users, contact your Splunk "
"Enterprise or Splunk Cloud Platform administrator."
msgstr ""

#: ../../logs/LOconnect-troubleshoot.rst:24
msgid "Solution"
msgstr ""

#: ../../logs/LOconnect-troubleshoot.rst:25
msgid ""
"To limit Splunk platform indexes for Log Observer Connect users, a Splunk"
" Enterprise or Splunk Cloud Platform administrator must follow these "
"steps:"
msgstr ""

#: ../../logs/LOconnect-troubleshoot.rst:27
msgid "Log in as an administrator in your Splunk platform instance."
msgstr ""

#: ../../logs/LOconnect-troubleshoot.rst:29
msgid ""
"Splunk Cloud Platform administrators can skip this step. If the "
"``indexes_list_all`` capability is not present in your Splunk Enterprise "
"instance, create a ``[capability::indexes_list_all]`` stanza in "
"``authorize.conf``. Once the configuration is set in ``authorize.conf``, "
"the ``indexes_list_all`` capability is disabled for all roles. The "
"administrator can then add this capability for select roles in the UI or "
"in ``authorize.conf``."
msgstr ""

#: ../../logs/LOconnect-troubleshoot.rst:30
msgid ""
"Enable ``indexes_list_all`` capability for the admin role and any other "
"roles that need to access the indexes. For more information about adding "
"capabilities to a role, see :new-page:`Define roles on the Splunk "
"plaftorm with capabilities "
"<https://docs.splunk.com/Documentation/Splunk/9.0.4/Security/Rolesandcapabilities>`."
msgstr ""

#: ../../logs/LOconnect-troubleshoot.rst:32
msgid ""
"Go to :guilabel:`Settings > Roles` and click the name of your Log "
"Observer Connect service account role."
msgstr ""

#: ../../logs/LOconnect-troubleshoot.rst:34
msgid ""
"On the :guilabel:`Capabilities` tab, deselect ``indexes_list_all`` to "
"prevent Log Observer Connect users from seeing all Splunk platform "
"indexes."
msgstr ""

#: ../../logs/aggregations.rst:-1
msgid ""
"Identify problems using log aggregation. Aggregate log records in groups,"
" then perform analyses to see averages, sums, and other statistics for "
"related logs."
msgstr ""

#: ../../logs/aggregations.rst:5
msgid "Group logs by fields using log aggregation"
msgstr ""

#: ../../logs/aggregations.rst:10
msgid ""
"Aggregations group related data by one field and then perform a "
"statistical calculation on other fields. Aggregating log records helps "
"you visualize problems by showing averages, sums, and other statistics "
"for related logs."
msgstr ""

#: ../../logs/aggregations.rst:15
msgid ""
"For example, suppose that you're browsing the Logs table to learn more "
"about the performance of your services. If you're concerned about the "
"response time of each service, you can group log records by service URL "
"and calculate average response time using an aggregation. This "
"aggregation helps you identify services that are responding slowly."
msgstr ""

#: ../../logs/aggregations.rst:21
msgid ""
"After you identify services with poor response time, you can drill down "
"in the log records for the service to understand the problems in more "
"detail."
msgstr ""

#: ../../logs/aggregations.rst:25
msgid "Aggregate log records"
msgstr ""

#: ../../logs/aggregations.rst:27
msgid "To perform an aggregation, follow these steps:"
msgstr ""

#: ../../logs/aggregations.rst:29
msgid ""
"Find the aggregations control bar. Log Observer Connect has no default "
"aggregation. Log Observer defaults to :strong:`Group by: severity`. This "
"default corresponds to the following aggregation controls settings:"
msgstr ""

#: ../../logs/aggregations.rst:31
msgid ":guilabel:`COUNT`"
msgstr ""

#: ../../logs/aggregations.rst:32
msgid ":guilabel:`All(*)`"
msgstr ""

#: ../../logs/aggregations.rst:33
msgid ":guilabel:`Group by`: severity"
msgstr ""

#: ../../logs/aggregations.rst:35
msgid ""
"To change the field to group by, type the field name in the "
":guilabel:`Group by` text box and press Enter. The aggregations control "
"bar also has these features:"
msgstr ""

#: ../../logs/aggregations.rst:37
msgid ""
"When you click in the text box, Log Observer displays a drop-down list "
"containing all the fields available in the log records."
msgstr ""

#: ../../logs/aggregations.rst:38
msgid "The text box does auto-search. To find a field, start typing its name."
msgstr ""

#: ../../logs/aggregations.rst:39
msgid "To select a field in the list, click its name."
msgstr ""

#: ../../logs/aggregations.rst:40
msgid ""
"When searching for a field to group by, you can only view 50 fields at a "
"time. Continue typing to see a more and more specific list of fields to "
"choose from."
msgstr ""

#: ../../logs/aggregations.rst:42
msgid ""
"To change the calculation you want to apply to each group, follow these "
"steps:"
msgstr ""

#: ../../logs/aggregations.rst:44
msgid ""
"Select the type of statistic from the calculation control. For example, "
"to calculate a mean value, select :menuselection:`AVG`."
msgstr ""

#: ../../logs/aggregations.rst:46
msgid ""
"Choose the field for the statistic by typing its name in the calculation "
"field control text box. The text box does auto-search, so start typing to"
" find matching field names."
msgstr ""

#: ../../logs/aggregations.rst:48
msgid "To perform the aggregation, click :guilabel:`Apply`."
msgstr ""

#: ../../logs/aggregations.rst:50
msgid ""
"Whenever you use a field for grouping or calculation, the results shown "
"in the Timeline histogram and Logs table include only logs containing "
"that field. Logs are implicitly filtered by the field you group by, "
"ensuring that calculations are not impacted by logs that do not contain "
"the field you used."
msgstr ""

#: ../../logs/aggregations.rst:53
msgid "Example 1: Identify problems by aggregating severity by service name"
msgstr ""

#: ../../logs/aggregations.rst:55
msgid ""
"One way you can discover potential problems is to find services that are "
"generating a high number of severe errors. To find these services, group "
"log records by service name and count all the records. Services with "
"problems appear as groups with many records that have a ``severity`` "
"value of ERROR."
msgstr ""

#: ../../logs/aggregations.rst:60 ../../logs/aggregations.rst:79
msgid "To apply this aggregation, follow these steps:"
msgstr ""

#: ../../logs/aggregations.rst:62
msgid ""
"Using the calculation control, set the calculation type by selecting "
":guilabel:`COUNT`."
msgstr ""

#: ../../logs/aggregations.rst:63
msgid ""
"Using the calculation field control, set the calculation field to "
":guilabel:`All(*)`."
msgstr ""

#: ../../logs/aggregations.rst:64
msgid ""
"Using the :guilabel:`Group by` text box, set the field to group by to "
"``service.name``."
msgstr ""

#: ../../logs/aggregations.rst:65
msgid ""
"Click :guilabel:`Apply`. The Timeline histogram displays a count of logs "
"by all your services as stacked columns, in which each severity value has"
" a different color. The histogram legend identifies the color of each "
"severity."
msgstr ""

#: ../../logs/aggregations.rst:71
msgid "Example 2: Identify problems by aggregating response time by request path"
msgstr ""

#: ../../logs/aggregations.rst:73
msgid ""
"Longer than expected service response might indicate a problem with the "
"service or other part of the host on which it runs. To identify services "
"that are responding more slowly than expected, group log events by "
"``http.req.path``, a field that uniquely identifies each service. For "
"each group, calculate the mean of the response time field "
"``http.resp.took_ms``."
msgstr ""

#: ../../logs/aggregations.rst:81
msgid "Using the calculation control, set calculation type to :guilabel:`AVG`."
msgstr ""

#: ../../logs/aggregations.rst:82
msgid ""
"Using the calculation field control, set the field to "
":guilabel:`http.resp.took_ms`"
msgstr ""

#: ../../logs/aggregations.rst:83
msgid ""
"Using the :guilabel:`Group by` text box, set the field to group by to "
"``http.req.path``."
msgstr ""

#: ../../logs/aggregations.rst:84
msgid ""
"Click :guilabel:`Apply`. The Timeline histogram displays the average "
"response time for each service."
msgstr ""

#: ../../logs/alias.rst:-1
msgid ""
"Aliases are alternate names for a field that allows you to search for it "
"by multiple names. Aliasing does not rename or remove the original field."
msgstr ""

#: ../../logs/alias.rst:5
msgid "Create field aliases"
msgstr ""

#: ../../logs/alias.rst:10
msgid ""
"An alias is an alternate name that you assign to a field, allowing you to"
" use that name to search for events that contain that field. An alias is "
"added to the event alongside the original field name to make it easier to"
" find the data you want and to connect your data sources through "
":ref:`Related Content <get-started-relatedcontent>` suggestions."
msgstr ""

#: ../../logs/alias.rst:12
msgid ""
":strong:`Field Aliasing` occurs at search time, not index time, so it "
"does not transform your data. Field Aliasing does not rename or remove "
"the original field name. When you alias a field, you can search for it by"
" its original name or by any of its aliases."
msgstr ""

#: ../../logs/alias.rst:15
msgid "When to use Field Aliasing"
msgstr ""

#: ../../logs/alias.rst:16
msgid "Use Field Aliasing when the following situations are true:"
msgstr ""

#: ../../logs/alias.rst:18
msgid ""
"You use Log Observer Connect to get logs data, and do not have access to "
"Log Observer Pipeline Management."
msgstr ""

#: ../../logs/alias.rst:19
msgid ""
"You do not want to use any indexing capacity by creating additional log "
"processing rules."
msgstr ""

#: ../../logs/alias.rst:20
msgid ""
"You want to retain your original field names, so you do not want to "
"create a log processing rule, which transforms your data at index time."
msgstr ""

#: ../../logs/alias.rst:21
msgid ""
"You want the new alias to affect every log message, even those that came "
"in from a time before you created the alias."
msgstr ""

#: ../../logs/alias.rst:22
msgid ""
"You want to display a field separately at the top of the log details "
"flyout"
msgstr ""

#: ../../logs/alias.rst:26
msgid "Field Aliasing examples"
msgstr ""

#: ../../logs/alias.rst:29
msgid "Displaying a field separately in the log details flyout"
msgstr ""

#: ../../logs/alias.rst:30
msgid ""
"For convenience, your team can choose to always display a particular "
"field separately at the top of the log details flyout. To display the "
"field of your choice separately, alias the desired field to the "
"``message`` field. The log details flyout in Log Observer always displays"
" the ``message`` field at the top. When you alias another field to the "
"``message`` field, it appears in the standalone section called "
":strong:`MESSAGE` at the top of the log details flyout."
msgstr ""

#: ../../logs/alias.rst:32
msgid ""
"For example, say your team most frequently uses the ``summary`` field. "
"Add an alias for the ``summary`` field called ``message``. The "
"``summary`` field still exists but is also known as ``message`` and "
"appears in the :strong:`MESSAGE` section of the log details flyout on the"
" right side of the screen."
msgstr ""

#: ../../logs/alias.rst:-1 ../../logs/message-field.rst:-1
msgid ""
"This image shows the location of the message field in a separate section "
"at the top of the log details flyout."
msgstr ""

#: ../../logs/alias.rst:39
msgid "Enabling Related Content"
msgstr ""

#: ../../logs/alias.rst:40
msgid ""
"For example, say Observability Cloud receives the following telemetry "
"data:"
msgstr ""

#: ../../logs/alias.rst:42
msgid ""
"Splunk APM receives a trace with the metadata field ``trace_id: "
"2b78e7c951497655``"
msgstr ""

#: ../../logs/alias.rst:43
msgid ""
"Splunk Log Observer receives a log with the metadata field "
"``trace.id:2b78e7c951497655``"
msgstr ""

#: ../../logs/alias.rst:45
msgid ""
"Although these refer to the same trace ID value, the log and the trace "
"cannot be correlated in Observability Cloud because the field names, "
"``trace_id`` and ``trace.id`` do not match. In this case, alias your log "
"metadata field ``trace.id`` to ``trace_id`` using Field Aliasing. When "
"the field names in APM and Log Observer match, the trace and the log with"
" the same trace ID value can be correlated in Observability Cloud. Then "
"when you are viewing the trace in APM, you can click directly into the "
"log with the same trace ID value and view the correlated log in Log "
"Observer."
msgstr ""

#: ../../logs/alias.rst:48
msgid "Normalizing field names"
msgstr ""

#: ../../logs/alias.rst:49
msgid ""
"One data source might have a field called ``http_referrer``. This field "
"might be misspelled in your source data as ``http_referer``. Use field "
"aliases to capture the misspelled field in your original source data and "
"map it to the expected field name without modifying your logging code."
msgstr ""

#: ../../logs/alias.rst:51
msgid ""
"You may have two data sources that call the same field by somewhat "
"different names. For example, one data source might have a field called "
"``EventID`` while another data source might have a field called "
"``EventRecordID``. You can tell by the values that these fields represent"
" the same thing. You can create a field alias that maps ``EventID`` to "
"``EventRecordID`` to aggregate all logs with either of those field names "
"to the field ``EventRecordID`` for analysis in Log Observer."
msgstr ""

#: ../../logs/alias.rst:54
msgid "Create a new field alias"
msgstr ""

#: ../../logs/alias.rst:55
msgid "To create a new field alias, follow these steps:"
msgstr ""

#: ../../logs/alias.rst:57
msgid ""
"In Splunk Observability Cloud navigation menu, go to :guilabel:`Settings "
"> Log Field Aliasing` and click :guilabel:`Add a new alias`."
msgstr ""

#: ../../logs/alias.rst:59
msgid ""
"In :guilabel:`Original field name`, enter the name of the field you want "
"to create an alias for. Start typing then select the field name you want "
"from the drop-down list of all available fields."
msgstr ""

#: ../../logs/alias.rst:61
msgid ""
"In :guilabel:`Alias`, enter the new name that you want this field to have"
" in addition to its original name. A list of other existing field names "
"appears in the drop-down list. Click :guilabel:`Save and Activate`."
msgstr ""

#: ../../logs/alias.rst:63
msgid "Click :guilabel:`Save and Activate`."
msgstr ""

#: ../../logs/alias.rst:65
msgid ""
"Your new field alias appears in Your aliases and defaults to active. It "
"is now applied to your search-time queries. To deactivate the alias, find"
" the field in Your aliases and click the toggle next to Active."
msgstr ""

#: ../../logs/alias.rst:69
msgid "Deactivate or delete a field alias"
msgstr ""

#: ../../logs/alias.rst:70
msgid ""
"You can deactivate or delete a field alias if you do not want the alias "
"to be applied to your search-time queries. You cannot edit a field alias."
" Instead, you must delete it and create a new one."
msgstr ""

#: ../../logs/alias.rst:72
msgid "To deactivate or delete a field alias, do the following:"
msgstr ""

#: ../../logs/alias.rst:74
msgid "Go to :guilabel:`Settings > Log Field Aliasing`."
msgstr ""

#: ../../logs/alias.rst:76
msgid "Find the alias you want to deactivate or delete in the Your aliases list."
msgstr ""

#: ../../logs/alias.rst:78
msgid ""
"To deactivate the alias, click the toggle next to :guilabel:`Active` in "
"the :guilabel:`STATUS` column. To delete the alias, click the trash icon "
"in the row for that alias."
msgstr ""

#: ../../logs/get-started-logs.rst:-1
msgid ""
"Get started investigating issues with Splunk Log Observer. Resolve "
"incidents faster through log filtering, aggregations, and analysis."
msgstr ""

#: ../../logs/get-started-logs.rst:5
msgid "Introduction to Splunk Log Observer"
msgstr ""

#: ../../logs/get-started-logs.rst:12
msgid ""
"If you do not have a Log Observer entitlement and instead use Log "
"Observer Connect, see :ref:`logs-intro-logconnect`."
msgstr ""

#: ../../logs/get-started-logs.rst:16
msgid "What is Log Observer?"
msgstr ""

#: ../../logs/get-started-logs.rst:18
msgid ""
"Troubleshoot your application and infrastructure behavior using high-"
"context logs in these applications:"
msgstr ""

#: ../../logs/get-started-logs.rst:20
msgid "Log Observer"
msgstr ""

#: ../../logs/get-started-logs.rst:21
msgid "Log Observer Connect"
msgstr ""

#: ../../logs/get-started-logs.rst:23
msgid ""
"In Log Observer, you can perform codeless queries on logs to detect the "
"source of problems in your systems. You can also extract fields from logs"
" to set up log processing rules and transform your data as it arrives or "
"send data to Infinite Logging S3 buckets for future use. See "
":ref:`LogObserverFeatures` to learn more about Log Observer capabilities."
msgstr ""

#: ../../logs/get-started-logs.rst:26
msgid ""
"In Log Observer Connect, you can perform codeless queries on your Splunk "
"Enterprise or Splunk Cloud Platform logs. See :ref:`logs-intro-"
"logconnect` to learn what you can do with the Splunk platform "
"integration."
msgstr ""

#: ../../logs/get-started-logs.rst:32
msgid "What can I do with Log Observer?"
msgstr ""

#: ../../logs/get-started-logs.rst:33
msgid ""
"The following table lists features available to customers with a Log "
"Observer entitlement. If you don't have a Log Observer entitlement in "
"Observability Cloud, see :ref:`logs-intro-logconnect` to discover "
"features available to customers of the Splunk platform integration."
msgstr ""

#: ../../logs/get-started-logs.rst:39 ../../logs/intro-logconnect.rst:31
msgid ":strong:`Do this`"
msgstr ""

#: ../../logs/get-started-logs.rst:40 ../../logs/intro-logconnect.rst:32
msgid ":strong:`With this tool`"
msgstr ""

#: ../../logs/get-started-logs.rst:41 ../../logs/intro-logconnect.rst:33
msgid ":strong:`Link to documentation`"
msgstr ""

#: ../../logs/get-started-logs.rst:43
msgid ""
"View your incoming logs grouped by severity over time and zoom in or out "
"to the time period of your choice."
msgstr ""

#: ../../logs/get-started-logs.rst:44 ../../logs/intro-logconnect.rst:36
msgid "Timeline"
msgstr ""

#: ../../logs/get-started-logs.rst:45 ../../logs/intro-logconnect.rst:37
#: ../../logs/lo-connect-landing.rst:43 ../../logs/log-observer-landing.rst:42
msgid ":ref:`logs-timeline`"
msgstr ""

#: ../../logs/get-started-logs.rst:47
msgid "Create a chart to see trends in your logs."
msgstr ""

#: ../../logs/get-started-logs.rst:48 ../../logs/metricization.rst:20
msgid "Log metricization rules"
msgstr ""

#: ../../logs/get-started-logs.rst:49 ../../logs/log-observer-landing.rst:70
msgid ":ref:`logs-metricization`"
msgstr ""

#: ../../logs/get-started-logs.rst:51 ../../logs/intro-logconnect.rst:43
msgid "Find out which path in your API has the slowest response time."
msgstr ""

#: ../../logs/get-started-logs.rst:52 ../../logs/intro-logconnect.rst:44
msgid "Log aggregations"
msgstr ""

#: ../../logs/get-started-logs.rst:53 ../../logs/intro-logconnect.rst:45
#: ../../logs/lo-connect-landing.rst:57 ../../logs/log-observer-landing.rst:58
#: ../../logs/queries.rst:20
msgid ":ref:`logs-aggregations`"
msgstr ""

#: ../../logs/get-started-logs.rst:55
msgid ""
"Filter your logs to see only logs that contain the field "
":guilabel:`error`."
msgstr ""

#: ../../logs/get-started-logs.rst:56 ../../logs/intro-logconnect.rst:40
#: ../../logs/intro-logconnect.rst:52
msgid "Logs table"
msgstr ""

#: ../../logs/get-started-logs.rst:57 ../../logs/intro-logconnect.rst:49
#: ../../logs/intro-logconnect.rst:53 ../../logs/lo-connect-landing.rst:49
#: ../../logs/log-observer-landing.rst:50 ../../logs/queries.rst:16
msgid ":ref:`logs-keyword`"
msgstr ""

#: ../../logs/get-started-logs.rst:59
msgid "Redact data to mask personally identifiable information in your logs."
msgstr ""

#: ../../logs/get-started-logs.rst:60 ../../logs/processors.rst:221
msgid "Field redaction processors"
msgstr ""

#: ../../logs/get-started-logs.rst:61
msgid ":ref:`field-redaction-processors`"
msgstr ""

#: ../../logs/get-started-logs.rst:63
msgid "Confirm that a recent fix stopped a problem."
msgstr ""

#: ../../logs/get-started-logs.rst:64
msgid "Live Tail"
msgstr ""

#: ../../logs/get-started-logs.rst:65 ../../logs/log-observer-landing.rst:44
msgid ":ref:`logs-live-tail`"
msgstr ""

#: ../../logs/get-started-logs.rst:67
msgid ""
"Apply processing rules across historical data to find a problem in the "
"past."
msgstr ""

#: ../../logs/get-started-logs.rst:68
msgid "Search-time rules"
msgstr ""

#: ../../logs/get-started-logs.rst:69 ../../logs/log-observer-landing.rst:60
msgid ":ref:`logs-search-time-rules`"
msgstr ""

#: ../../logs/get-started-logs.rst:71
msgid ""
"Transform your data or a subset of your data as it arrives in "
"Observability Cloud."
msgstr ""

#: ../../logs/get-started-logs.rst:72 ../../logs/metricization.rst:18
msgid "Log processing rules"
msgstr ""

#: ../../logs/get-started-logs.rst:73 ../../logs/log-observer-landing.rst:68
msgid ":ref:`logs-processors`"
msgstr ""

#: ../../logs/get-started-logs.rst:75
msgid ""
"Minimize expense by archiving unindexed logs in Amazon S3 buckets for "
"potential future use."
msgstr ""

#: ../../logs/get-started-logs.rst:76
msgid "Infinite Logging rules"
msgstr ""

#: ../../logs/get-started-logs.rst:77 ../../logs/log-observer-landing.rst:72
msgid ":ref:`logs-infinite`"
msgstr ""

#: ../../logs/get-started-logs.rst:79 ../../logs/intro-logconnect.rst:59
msgid "See the metrics, traces, and infrastructure related to a specific log."
msgstr ""

#: ../../logs/get-started-logs.rst:80 ../../logs/intro-logconnect.rst:60
msgid "Related Content"
msgstr ""

#: ../../logs/get-started-logs.rst:81 ../../logs/intro-logconnect.rst:61
msgid ":ref:`get-started-scenario`"
msgstr ""

#: ../../logs/get-started-logs.rst:86
msgid "Get started with Log Observer"
msgstr ""

#: ../../logs/get-started-logs.rst:87
msgid ""
"If you have a Log Observer entitlement and want to set up Log Observer "
"and start performing queries on your logs, see :ref:`logs-logs`."
msgstr ""

#: ../../logs/get-started-logs.rst:89
msgid ""
"If you don't have a Log Observer entitlement in Observability Cloud, see "
":ref:`logs-set-up-logconnect` or :ref:`logs-scp` to learn how to set up "
"Log Observer Connect and begin querying your Splunk platform logs."
msgstr ""

#: ../../logs/individual-log.rst:-1
msgid ""
"View and search a log's fields and values in JSON. Link to related "
"content. Extract a field to create a processing rule."
msgstr ""

#: ../../logs/individual-log.rst:5
msgid "View individual log details and create a field extraction processor"
msgstr ""

#: ../../logs/individual-log.rst:10
msgid ""
"After you find a set of log records that contain specific useful "
"information, you can view the contents of an individual record to get a "
"complete view of the data in the log, broken down by fields and values "
"and displayed in JSON format in the :strong:`Fields` panel. You can also "
"see the number of times each field appears in all of your logs."
msgstr ""

#: ../../logs/individual-log.rst:12
msgid ""
"Once you have identified an interesting field, you can perform a field "
"extraction and use it to transform your data. See :ref:`logs-processors` "
"for more information."
msgstr ""

#: ../../logs/individual-log.rst:14
msgid ""
"Only customers with a Splunk Log Observer entitlement in Splunk "
"Observability Cloud can create a field extraction processor. If you are "
"using Log Observer Connect, you can view and search Splunk Cloud Platform"
" or Splunk Enterprise data in Log Observer, but you cannot transform it."
msgstr ""

#: ../../logs/individual-log.rst:17
msgid ""
"To view the contents of an individual log record and create a field "
"extraction rule, follow these steps:"
msgstr ""

#: ../../logs/individual-log.rst:19
msgid ""
"Select a log record line in the Logs table to display the Log Details "
"panel."
msgstr ""

#: ../../logs/individual-log.rst:21
msgid ""
"This panel displays the entire record in JSON format as well as a table "
"of each field and its value."
msgstr ""

#: ../../logs/individual-log.rst:23
msgid "To do more with a particular field in the table, select the field value."
msgstr ""

#: ../../logs/individual-log.rst:25
msgid "Log Observer displays a drop-down list with 5 options:"
msgstr ""

#: ../../logs/individual-log.rst:27
#: ../../logs/logs-individual-log-connect.rst:23
msgid "To copy the field value to the clipboard, select :menuselection:`Copy`"
msgstr ""

#: ../../logs/individual-log.rst:28
#: ../../logs/logs-individual-log-connect.rst:24
msgid ""
"To filter to the Logs table so it only displays log records containing "
"the selected value, select :menuselection:`Add to filter`."
msgstr ""

#: ../../logs/individual-log.rst:29
#: ../../logs/logs-individual-log-connect.rst:25
msgid ""
"To filter the Logs table so it doesn't display log records containing the"
" selected value, select :menuselection:`Exclude from filter`."
msgstr ""

#: ../../logs/individual-log.rst:30
msgid ""
"To create a new log processing rule based on the selected field, select "
":menuselection:`Extract Field`. To learn more about extracting fields to "
"create log processors, see :new-page-ref:`logs-processors`."
msgstr ""

#: ../../logs/individual-log.rst:31
#: ../../logs/logs-individual-log-connect.rst:26
msgid ""
"To add the field as a new column in the  Logs table, select "
":menuselection:`Add field as column`."
msgstr ""

#: ../../logs/individual-log.rst:32
#: ../../logs/logs-individual-log-connect.rst:27
msgid ""
"Select :menuselection:`View <field_name>` to go to the appropriate view "
"in the Splunk Observability Cloud. For example, if you select a field "
"related to Kubernetes, Observability Cloud displays related data in the "
"Kubernetes Navigator. If you select fields related to APM, such as "
":menuselection:`View trace_id` or :menuselection:`View span_id`, "
"Observability Cloud displays the trace or span in the APM Navigator."
msgstr ""

#: ../../logs/infinite.rst:-1
msgid ""
"Archive logs in Amazon S3 buckets using infinite logging rules. Reduce "
"the amount of logs data you index. Increase logs' retention period."
msgstr ""

#: ../../logs/infinite.rst:5
msgid "Archive your logs with infinite logging rules"
msgstr ""

#: ../../logs/infinite.rst:10
msgid ""
"Only customers with a Splunk Log Observer entitlement in Splunk "
"Observability Cloud can create infinite logging rules. If you do not have"
" a Log Observer entitlement and are using Splunk Log Observer Connect "
"instead, see :ref:`logs-intro-logconnect` to learn what you can do with "
"the Splunk Enterprise integration."
msgstr ""

#: ../../logs/infinite.rst:12
msgid ""
"Create infinite logging rules to archive all or any subset of logs in "
"Amazon S3 buckets for compliance or possible future use while not paying "
"to index them unless and until you want to analyze them in Splunk Log "
"Observer."
msgstr ""

#: ../../logs/infinite.rst:15
msgid "Use cases for archiving your logs"
msgstr ""

#: ../../logs/infinite.rst:16
msgid "There are two primary use cases to archive your logs:"
msgstr ""

#: ../../logs/infinite.rst:18
msgid ":ref:`To reduce the amount of data you index <logs-reduce>`"
msgstr ""

#: ../../logs/infinite.rst:20
msgid ":ref:`To retain logs data longer than 30 days <logs-retain>`"
msgstr ""

#: ../../logs/infinite.rst:25
msgid "Reduce the amount of data you indexed"
msgstr ""

#: ../../logs/infinite.rst:26
msgid ""
"Some logs may not be useful on a day-to-day basis but may still be "
"important in case of a future incident. For example, you might not always"
" want to index logs from a non-production environment, or index every "
"debug message. In either case, you can create an infinite logging rule to"
" archive those logs in S3 buckets that your team owns in AWS."
msgstr ""

#: ../../logs/infinite.rst:28
msgid ""
"If you want to keep a sample of your archived logs to analyze in Log "
"Observer, you can set the sampling rate in your infinite logging rule so "
"that some amount of the data you archive will also be indexed. You pay "
"for only the logs that you index and analyze in Log Observer. This way, "
"you can monitor trends across all your logs while reducing the impact on "
"your indexing capacity. See :ref:`order-of-execution` in the next section"
" to learn more about using pipeline rules to help reduce your indexing "
"capacity."
msgstr ""

#: ../../logs/infinite.rst:33
msgid "Retain logs longer than 30 days"
msgstr ""

#: ../../logs/infinite.rst:34
#, python-format
msgid ""
"Storing logs in S3 buckets gives you full control over retention time, "
"which can, for example, help you meet compliance and audit requirements. "
"To retain logs longer than Log Observer’s 30-day retention period, you "
"can archive and index 100% of your logs. Logs that are archived and "
"indexed will be available for analysis in Log Observer for 30 days and "
"will also be stored in S3 buckets for as long as you want them."
msgstr ""

#: ../../logs/infinite.rst:39 ../../logs/metricization.rst:15
#: ../../logs/processors.rst:37
msgid "Order of execution of logs pipeline rules"
msgstr ""

#: ../../logs/infinite.rst:40 ../../logs/metricization.rst:16
#: ../../logs/pipeline.rst:24 ../../logs/processors.rst:38
msgid "Logs pipeline rules execute in the following order:"
msgstr ""

#: ../../logs/infinite.rst:42 ../../logs/pipeline.rst:26
#: ../../logs/processors.rst:40
msgid ""
"All log processing rules (field extraction, field copy, and field "
"redaction processors)"
msgstr ""

#: ../../logs/infinite.rst:44 ../../logs/pipeline.rst:28
#: ../../logs/processors.rst:42
msgid "All log metricization rules"
msgstr ""

#: ../../logs/infinite.rst:46 ../../logs/processors.rst:44
msgid "All infinite logging rules"
msgstr ""

#: ../../logs/infinite.rst:48
msgid ""
"Because infinite logging rules execute last, you can create field "
"extraction rules, then use the resulting fields in infinite logging "
"rules. You can also metricize logs, then archive them via infinite "
"logging without impacting your ingest capacity. For more information, see"
" :ref:`logs-pipeline-sequence`."
msgstr ""

#: ../../logs/infinite.rst:51 ../../logs/logs.rst:24 ../../logs/scp.rst:21
#: ../../logs/set-up-logconnect.rst:22
msgid "Prerequisites"
msgstr ""

#: ../../logs/infinite.rst:52
msgid ""
"You must be a Splunk Observability Cloud admin to create new infinite "
"logging connections. Non-admins can send data to S3 buckets using an "
"existing infinite logging connection, but they cannot create new "
"connections. See AWS documentation for permissions required to create S3 "
"buckets in the AWS Management Console."
msgstr ""

#: ../../logs/infinite.rst:55
msgid "Create an infinite logging rule"
msgstr ""

#: ../../logs/infinite.rst:57
msgid "To create an infinite logging rule, follow these steps:"
msgstr ""

#: ../../logs/infinite.rst:59 ../../logs/metricization.rst:42
msgid ""
"From the navigation menu, go to :guilabel:`Data Configuration > Logs "
"Pipeline Management`."
msgstr ""

#: ../../logs/infinite.rst:61
msgid "Click :guilabel:`New infinite logging Rule`."
msgstr ""

#: ../../logs/infinite.rst:63
msgid ""
"Decide where to archive your data. To send your logs to an existing S3 "
"bucket, click the infinite logging connection you want, then skip to step"
" 9."
msgstr ""

#: ../../logs/infinite.rst:65
msgid ""
"If you want to send your data to a new S3 bucket and you are an "
"Observability Cloud admin, click :guilabel:`Create new connection`. The "
":guilabel:`Establish a New S3 Connection` wizard appears."
msgstr ""

#: ../../logs/infinite.rst:67
msgid ""
"On the :guilabel:`Choose an AWS Region and Authentication Type` tab, do "
"the following:"
msgstr ""

#: ../../logs/infinite.rst:69
msgid "Select the AWS region you want to connect to."
msgstr ""

#: ../../logs/infinite.rst:70
msgid ""
"Select whether you want to use the :guilabel:`External ID` or "
":guilabel:`Security Token` authentication type."
msgstr ""

#: ../../logs/infinite.rst:71 ../../logs/infinite.rst:92
#: ../../logs/metricization.rst:52 ../../logs/metricization.rst:56
msgid "Click :guilabel:`Next`."
msgstr ""

#: ../../logs/infinite.rst:73
msgid ""
"On the :guilabel:`Prepare AWS Account` tab, follow the steps in the "
"wizard to do the following in the AWS Management Console:"
msgstr ""

#: ../../logs/infinite.rst:75
msgid ""
"Create an AWS policy. The wizard provides the exact policy you must copy "
"and paste into AWS."
msgstr ""

#: ../../logs/infinite.rst:76
msgid "Create a role and associate it with the AWS policy."
msgstr ""

#: ../../logs/infinite.rst:77
msgid "Create and configure an S3 bucket."
msgstr ""

#: ../../logs/infinite.rst:79
msgid "On the :guilabel:`Establish Connection` tab, do the following:"
msgstr ""

#: ../../logs/infinite.rst:81
msgid "Give your new S3 connection a name."
msgstr ""

#: ../../logs/infinite.rst:82
msgid ""
"Paste the Role ARN from the AWS Management Console into the "
":guilabel:`Role ARN` field in the wizard."
msgstr ""

#: ../../logs/infinite.rst:83
msgid "Give your S3 bucket a name."
msgstr ""

#: ../../logs/infinite.rst:84
msgid "Click :guilabel:`Save`."
msgstr ""

#: ../../logs/infinite.rst:86
msgid ""
"Choose the Amazon S3 infinite logging connection that you created on the "
"first page of the wizard. Your data will go to your S3 bucket in a file "
"that you configure in the following two steps."
msgstr ""

#: ../../logs/infinite.rst:88
msgid ""
"(Optional) You can add a file prefix, which will be prepended to the "
"front of the file you send to your S3 bucket."
msgstr ""

#: ../../logs/infinite.rst:90
msgid ""
"(Optional) In :guilabel:`Advanced Configuration Options`, you can select "
"the compression and file formats of the file you will send to your S3 "
"bucket."
msgstr ""

#: ../../logs/infinite.rst:94
msgid ""
"On the :strong:`Filter Data` page, create a filter that matches the log "
"lines you want to archive in your S3 bucket. Only logs matching the "
"filter are archived. If you want to index a sample of the logs being sent"
" to the archive, select a percentage in :guilabel:`Define indexing "
"behavior`. Indexing a small percentage of logs in Log Observer allows you"
" to see trends in logs that are stored in S3 buckets. Click "
":guilabel:`Next`."
msgstr ""

#: ../../logs/infinite.rst:96
msgid "Add a name and description for your infinite logging rule."
msgstr ""

#: ../../logs/infinite.rst:98
msgid "Review your configuration choices, then click :guilabel:`Save`."
msgstr ""

#: ../../logs/infinite.rst:100
msgid ""
"Your infinite logging setup is now complete. Depending on your "
"selections, your logs will be archived, indexed in Observability Cloud "
"for analysis, or both."
msgstr ""

#: ../../logs/infinite.rst:103
msgid "Infinite logging rules limits"
msgstr ""

#: ../../logs/infinite.rst:104
msgid "An organization can create a total of 128 infinite logging rules."
msgstr ""

#: ../../logs/intro-logconnect.rst:-1
msgid ""
"Log Observer integration with Splunk Cloud Platform or Splunk Enterprise."
" The introduction is an overview describing all Log Observer Connect "
"functionality."
msgstr ""

#: ../../logs/intro-logconnect.rst:5
msgid "Introduction to Splunk Log Observer Connect"
msgstr ""

#: ../../logs/intro-logconnect.rst:13
msgid ""
"If you have a Log Observer entitlement rather than Log Observer Connect, "
"see :ref:`get-started-logs`."
msgstr ""

#: ../../logs/intro-logconnect.rst:15
msgid ""
"Splunk Log Observer Connect is an integration that allows you to query "
"your Splunk Enterprise or Splunk Cloud Platform logs using the "
"capabilities of Splunk Log Observer and :ref:`Related Content <get-"
"started-relatedcontent>` in Splunk Observability Cloud. With Log Observer"
" Connect, you can troubleshoot your application and infrastructure "
"behavior using high-context logs. Perform codeless queries on your Splunk"
" Enterprise or Splunk Cloud Platform logs to detect the source of "
"problems in your systems, then jump to Related Content throughout Splunk "
"Observability Cloud in one click. Seeing your logs data correlated with "
"metrics and traces in Observability Cloud helps your team to locate and "
"resolve problems exponentially faster."
msgstr ""

#: ../../logs/intro-logconnect.rst:18 ../../logs/scp.rst:15
msgid "Region and version availability"
msgstr ""

#: ../../logs/intro-logconnect.rst:19
msgid ""
"Splunk Log Observer Connect is available in the AWS regions us0, us1, "
"eu0, jp0, and au0. Splunk Log Observer Connect is compatible with Splunk "
"Enterprise and Splunk Cloud Platform versions 8.2 and higher. Log "
"Observer Connect is not available for Splunk Cloud Platform trials."
msgstr ""

#: ../../logs/intro-logconnect.rst:21
msgid ""
"Customers cannot access logs from a GovCloud environment through Log "
"Observer Connect. However, you can use global data links to link from Log"
" Observer Connect to your GovCloud environment where you can access your "
"logs. For more information on global data links, see :ref:`link-metadata-"
"to-content`."
msgstr ""

#: ../../logs/intro-logconnect.rst:24
msgid "What can I do with Log Observer Connect?"
msgstr ""

#: ../../logs/intro-logconnect.rst:25
msgid ""
"The following table lists features available to customers who have "
"integrated Splunk Enterprise or Splunk Cloud Platform with Log Observer, "
"allowing them to use Log Observer Connect. If you have a Log Observer "
"entitlement in Observability Cloud, see :ref:`get-started-logs` for a "
"complete list of Log Observer features."
msgstr ""

#: ../../logs/intro-logconnect.rst:35
msgid ""
"View your incoming logs and zoom in or out to the time period of your "
"choice."
msgstr ""

#: ../../logs/intro-logconnect.rst:39
msgid "Scan logs."
msgstr ""

#: ../../logs/intro-logconnect.rst:41 ../../logs/lo-connect-landing.rst:47
#: ../../logs/log-observer-landing.rst:48 ../../logs/queries.rst:14
msgid ":ref:`logs-raw-logs-display`"
msgstr ""

#: ../../logs/intro-logconnect.rst:47
msgid "Search logs by keyword or field."
msgstr ""

#: ../../logs/intro-logconnect.rst:48
msgid "Content control bar"
msgstr ""

#: ../../logs/intro-logconnect.rst:51
msgid ""
"Filter your logs to see only logs that contain a field of your choice "
"with the value :guilabel:`error`."
msgstr ""

#: ../../logs/intro-logconnect.rst:55
msgid "View the JSON schema of an individual log."
msgstr ""

#: ../../logs/intro-logconnect.rst:56
msgid "Log details"
msgstr ""

#: ../../logs/intro-logconnect.rst:57 ../../logs/log-observer-landing.rst:54
#: ../../logs/queries.rst:18
msgid ":ref:`logs-individual-log`"
msgstr ""

#: ../../logs/intro-logconnect.rst:63
msgid "Save and share Log Observer queries."
msgstr ""

#: ../../logs/intro-logconnect.rst:64
msgid "Saved Queries"
msgstr ""

#: ../../logs/intro-logconnect.rst:65 ../../logs/lo-connect-landing.rst:59
#: ../../logs/log-observer-landing.rst:62
msgid ":ref:`logs-save-share`"
msgstr ""

#: ../../logs/intro-logconnect.rst:69
msgid "Get started with Log Observer Connect"
msgstr ""

#: ../../logs/intro-logconnect.rst:70
msgid ""
"If you manage Splunk Enterprise in a data center or public cloud and want"
" to begin using Log Observer Connect, see :ref:`logs-set-up-logconnect`. "
"If you use Splunk Cloud Platform and want to integrate Log Observer "
"Connect, see :ref:`logs-scp`."
msgstr ""

#: ../../logs/intro-logconnect.rst:72 ../../logs/set-up-logconnect.rst:19
msgid ""
"You can collect data using both the Splunk Distribution of OpenTelemetry "
"Collector and the Universal Forwarder without submitting any duplicate "
"telemetry data. See :ref:`collector-with-the-uf` to learn how."
msgstr ""

#: ../../logs/keyword.rst:-1
msgid "Search and filter logs by keyword, field, or field values."
msgstr ""

#: ../../logs/keyword.rst:5
msgid "Search logs by keywords or fields"
msgstr ""

#: ../../logs/keyword.rst:10
msgid ""
"You can search Splunk Observability Cloud logs if your Splunk "
"Observability Cloud instance ingests logs. If your organization has "
"integrated its Splunk platform (Splunk Cloud Platform or Splunk "
"Enterprise) instance with its Splunk Observability Cloud instance, you "
"can search Splunk platform logs that your Splunk platform role has "
"permissions to see in Splunk platform. If you cannot access a log in your"
" Splunk platform instance, you cannot access it in Splunk Observability "
"Cloud."
msgstr ""

#: ../../logs/keyword.rst:12
msgid ""
"You can search logs that you have permissions to see for particular "
"keywords, field names, or field values."
msgstr ""

#: ../../logs/keyword.rst:14
msgid "To search your logs, follow these steps:"
msgstr ""

#: ../../logs/keyword.rst:16
msgid ""
"Navigate to :guilabel:`Log Observer`. In the content control bar, enter a"
" time range in the time picker if you know it."
msgstr ""

#: ../../logs/keyword.rst:17
msgid ""
"Select :guilabel:`Index` next to :guilabel:`Saved Queries`, then select "
"the indexes you want to query. If you want to search your Splunk platform"
" (Splunk Cloud Platform or Splunk Enterprise) data, select the "
"integration for the appropriate Splunk platform instance first, then "
"select which index you want to query in Log Observer. You can only query "
"indexes from one Splunk platform instance or Observability Cloud instance"
" at a time. You can only query Splunk platform indexes if you have the "
"appropriate role and permissions in the Splunk platform instance. Select "
":guilabel:`Apply`."
msgstr ""

#: ../../logs/keyword.rst:18
msgid ""
"In the content control bar next to the index picker, select "
":guilabel:`Add Filter`."
msgstr ""

#: ../../logs/keyword.rst:19
msgid ""
"To search on a keyword, select the :guilabel:`Keyword` tab, type the "
"keyword or phrase you want to search on, then press Enter. If you want to"
" search on a field, select the :guilabel:`Fields` tab, enter the field "
"name, then press Enter."
msgstr ""

#: ../../logs/keyword.rst:20
msgid ""
"To continue adding keywords or fields to the search, select "
":guilabel:`Add Filter`."
msgstr ""

#: ../../logs/keyword.rst:21
msgid ""
"Review the top values for your query on the the :guilabel:`Fields` panel "
"on right. This list includes the count of each value in the log records. "
"To include log records with a particular value, select the field name, "
"then select ``=``. To exclude log records with a particular value from "
"your results, select the field name, then select ``!=``. To see the full "
"list of values and distribution for this field, select :guilabel:`Explore"
" all values`."
msgstr ""

#: ../../logs/keyword.rst:23
msgid ""
"When you add keywords, field names, or field values to the filters, Log "
"Observer narrows the results in the Timeline and the Logs table so that "
"only records containing the selected fields and values appear. To learn "
"how you can use a productive search in the future, see :ref:`logs-save-"
"share`."
msgstr ""

#: ../../logs/limits.rst:-1
msgid ""
"See Log Observer limits on MB of data ingested or indexed per month, "
"limits on the number and type of processing rules, and search query "
"limits."
msgstr ""

#: ../../logs/limits.rst:5
msgid "Log Observer limits"
msgstr ""

#: ../../logs/limits.rst:10
msgid ""
"This page documents Splunk Log Observer service limits and behavior. "
"System protection limits are meant to allow for stability and "
"availability of multi-tenant systems and are subject to fine-tuning and "
"change without notice."
msgstr ""

#: ../../logs/limits.rst:13
msgid "Log Observer ingest and index limits"
msgstr ""

#: ../../logs/limits.rst:15
msgid ""
"The following table lists Log Observer's log ingestion and indexing "
"limits:"
msgstr ""

#: ../../logs/limits.rst:21 ../../logs/limits.rst:66 ../../logs/limits.rst:92
#: ../../logs/lo-connect-limits.rst:21
msgid ":strong:`Limit name`"
msgstr ""

#: ../../logs/limits.rst:22 ../../logs/limits.rst:67 ../../logs/limits.rst:93
#: ../../logs/lo-connect-limits.rst:22
msgid ":strong:`Default limit value`"
msgstr ""

#: ../../logs/limits.rst:24 ../../logs/limits.rst:31
msgid "MB ingested per month"
msgstr ""

#: ../../logs/limits.rst:25 ../../logs/limits.rst:28
msgid "Determined by your subscription"
msgstr ""

#: ../../logs/limits.rst:27 ../../logs/limits.rst:45
msgid "MB indexed per month"
msgstr ""

#: ../../logs/limits.rst:33
msgid ""
"The :guilabel:`Log volume ingestion` entitlement is determined by your "
"organization's contract. It can be translated from Host purchased, or can"
" be based on GB usage per month. The amount of this monthly capacity that"
" you can use per hour or per minute, or \"burst limit\", is a multiple of"
" your contractual limit. You can increase your contract limit MB/month. "
"You cannot increase the burst limit MB/hour or MB/minute as it is a "
"system limit to ensure the protection of your data."
msgstr ""

#: ../../logs/limits.rst:35 ../../logs/limits.rst:49
msgid ""
":guilabel:`Important:` This limit is a system protection limit and is "
"subject to change based on system availability and fine-tuning."
msgstr ""

#: ../../logs/limits.rst:38 ../../logs/limits.rst:52 ../../logs/limits.rst:78
#: ../../logs/limits.rst:109 ../../logs/limits.rst:118
#: ../../logs/limits.rst:128 ../../logs/lo-connect-limits.rst:36
#: ../../logs/lo-connect-limits.rst:45
msgid "What happens when the limit is hit?"
msgstr ""

#: ../../logs/limits.rst:40
msgid ""
"Any log data that exceeds the limit in that bucket (hourly and minutely) "
"will be dropped and not ingested."
msgstr ""

#: ../../logs/limits.rst:42 ../../logs/limits.rst:55
msgid ""
"Splunk can increase this limit on a customer's request. The customer is "
"subject to overage charges."
msgstr ""

#: ../../logs/limits.rst:47
msgid ""
"The :guilabel:`Log volume indexed` entitlement is determined by your "
"organization's contract. It can be translated from Host purchased, or can"
" be based on GB usage per month. The amount of this monthly capacity that"
" you can use per hour or per minute, or \"burst limit\", is a multiple of"
" your contractual limit. You can increase your contract limit MB/month. "
"You cannot increase the burst limit MB/hour or MB/minute as it is a "
"system limit to ensure the protection of your data."
msgstr ""

#: ../../logs/limits.rst:53
msgid ""
"Any log data that exceeds the limit in that bucket (hourly and minutely) "
"will be dropped and not indexed.ß"
msgstr ""

#: ../../logs/limits.rst:58
msgid "Log Observer processing rule limits"
msgstr ""

#: ../../logs/limits.rst:60
msgid "The following table lists Log Observer's processing rule limits:"
msgstr ""

#: ../../logs/limits.rst:69 ../../logs/limits.rst:73
msgid "Maximum number of processing rules"
msgstr ""

#: ../../logs/limits.rst:70
msgid "128"
msgstr ""

#: ../../logs/limits.rst:75
msgid ""
"This is the maximum number of processing rules that an organization can "
"create. An organization can create 128 combined log processing rules, "
"including field extraction rules, field copy rules, and field redaction "
"rules. An organization can also create a total of 128 infinite logging "
"rules and 128 log metricization rules."
msgstr ""

#: ../../logs/limits.rst:79
msgid "No new log processing rules can be created."
msgstr ""

#: ../../logs/limits.rst:81
msgid ""
"Log Observer has a hard limit of 128 rules. Splunk cannot increase this "
"limit at a customer's request."
msgstr ""

#: ../../logs/limits.rst:84
msgid "Log Observer search query limits"
msgstr ""

#: ../../logs/limits.rst:86
msgid "The following table lists Log Observer's search query limits:"
msgstr ""

#: ../../logs/limits.rst:95 ../../logs/limits.rst:105
#: ../../logs/lo-connect-limits.rst:24 ../../logs/lo-connect-limits.rst:32
msgid "Maximum number of saved search queries"
msgstr ""

#: ../../logs/limits.rst:96 ../../logs/lo-connect-limits.rst:25
msgid "1,000"
msgstr ""

#: ../../logs/limits.rst:98
msgid "Maximum number of logs processed for Fields Summary"
msgstr ""

#: ../../logs/limits.rst:99 ../../logs/lo-connect-limits.rst:28
msgid "150,000"
msgstr ""

#: ../../logs/limits.rst:101 ../../logs/limits.rst:123
msgid "Maximum number of concurrent live tails"
msgstr ""

#: ../../logs/limits.rst:102
msgid "2,048"
msgstr ""

#: ../../logs/limits.rst:106 ../../logs/lo-connect-limits.rst:33
msgid ""
"This is the maximum number of saved search queries that can be created in"
" an organization."
msgstr ""

#: ../../logs/limits.rst:110 ../../logs/lo-connect-limits.rst:37
msgid "The user experience might degrade and is not guaranteed to be functional."
msgstr ""

#: ../../logs/limits.rst:113
msgid "Maximum number of logs processed for the Fields Summary"
msgstr ""

#: ../../logs/limits.rst:115
msgid ""
"The Log Observer UI displays a summary of fields and their value "
"distribution. By default, it processes the most recent 150,0000 events to"
" generate this view."
msgstr ""

#: ../../logs/limits.rst:120 ../../logs/lo-connect-limits.rst:47
msgid ""
"If the search results contain more than 150,000 events, then only the "
"latest 150,000 events are processed."
msgstr ""

#: ../../logs/limits.rst:125
msgid ""
"This is the maximum number of live tails that can be running at the same "
"time. These queries are dispatched as the user interacts with the Log "
"Observer Live Tail UI."
msgstr ""

#: ../../logs/limits.rst:130
msgid ""
"Additional live tail queries are queued until an existing live tail is "
"canceled. Live tail queries do not return data while queued."
msgstr ""

#: ../../logs/live-tail.rst:-1
msgid ""
"Live Tail shows a near real-time feed of log messages as they come into "
"Log Observer. See the impact of updates live. Verify that an integration "
"is sending data."
msgstr ""

#: ../../logs/live-tail.rst:5
msgid "Verify changes to monitored systems with Live Tail"
msgstr ""

#: ../../logs/live-tail.rst:10
msgid ""
"Only customers with a Splunk Log Observer entitlement in Splunk "
"Observability Cloud can monitor systems with Live Tail. If you do not "
"have a Log Observer entitlement and are using Splunk Log Observer Connect"
" instead, see :ref:`logs-intro-logconnect` to learn what you can do with "
"the Splunk Enterprise integration."
msgstr ""

#: ../../logs/live-tail.rst:12
msgid ""
"Live Tail displays a streaming view of log messages. Use Live Tail to do "
"the following:"
msgstr ""

#: ../../logs/live-tail.rst:14
msgid "Verify that an integration is sending data to Splunk Observability Cloud."
msgstr ""

#: ../../logs/live-tail.rst:15
msgid ""
"View spans and traces that your APM services are sending to Observability"
" Cloud."
msgstr ""

#: ../../logs/live-tail.rst:16
msgid "See the impact of configuration changes on your incoming data streams."
msgstr ""

#: ../../logs/live-tail.rst:20
msgid "View the Live Tail time range"
msgstr ""

#: ../../logs/live-tail.rst:22
msgid ""
"The Log Observer TimeLine time picker offers Live Tail as one of the time"
" ranges. In all other time ranges, the logs are already indexed by Splunk"
" Cloud Platform services. The logs displayed by Live Tail aren't indexed."
msgstr ""

#: ../../logs/live-tail.rst:27
msgid "Exit Live Tail"
msgstr ""

#: ../../logs/live-tail.rst:29
msgid ""
"To exit Live Tail and return to the Log Observer main page, use the time "
"picker in the navigation bar to select a different time range."
msgstr ""

#: ../../logs/live-tail.rst:33
msgid "The Live Tail display"
msgstr ""

#: ../../logs/live-tail.rst:35
msgid ""
"The Live Tail displays a sample of incoming logs because the amount of "
"log data is too large to display completely. Below the time picker menu "
"in the navigation bar, you can see the time when Live Tail started "
"displaying logs and the percentage of logs displayed. The number of logs "
"visible in Live Tail depends on the amount of data you're receiving."
msgstr ""

#: ../../logs/live-tail.rst:42
msgid "Adjust incoming log speed in Live Tail"
msgstr ""

#: ../../logs/live-tail.rst:44
msgid ""
"Because incoming data comes in quickly, you might have problems reading "
"the incoming logs. You can adjust the incoming log speed in the following"
" ways:"
msgstr ""

#: ../../logs/live-tail.rst:47
msgid ""
"Scroll the table. Scrolling freezes the table view, letting you read a "
"portion of the incoming log lines."
msgstr ""

#: ../../logs/live-tail.rst:49
msgid "Click :guilabel:`Stop` or :guilabel:`Play` in the navigation bar."
msgstr ""

#: ../../logs/live-tail.rst:50
#, python-format
msgid ""
"Adjust the log speed using the :guilabel:`Logs/Second` slider. Next to "
"the slider, you can see what percentage of logs are visible at the "
"selected rate. As you increase the rate of logs per second, the "
":guilabel:`Showing 100% of logs` callout adjusts accordingly."
msgstr ""

#: ../../logs/live-tail.rst:52
msgid ""
"When you are not viewing the most recent events, you can view the most "
"recent incoming event by clicking :guilabel:`Jump to recent` at the end "
"of the display."
msgstr ""

#: ../../logs/live-tail.rst:55
msgid ""
"The following examples use Live Tail to check that data is coming into "
"the Splunk Observability Suite after an integration with Kubernetes."
msgstr ""

#: ../../logs/live-tail.rst:59
msgid "Verify an integration using Live Tail"
msgstr ""

#: ../../logs/live-tail.rst:61
msgid ""
"To verify, for example, your integration of Kubernetes with Splunk "
"Observability Cloud, use one of of the techniques demonstrated in the "
"following examples:"
msgstr ""

#: ../../logs/live-tail.rst:64
msgid ":ref:`verify-integration-with-live-tail-filtering`"
msgstr ""

#: ../../logs/live-tail.rst:65
msgid ":ref:`verify-integration-with-live-tail-keyword-highlighting`"
msgstr ""

#: ../../logs/live-tail.rst:70
msgid "Example: Verify an integration with Live Tail filtering"
msgstr ""

#: ../../logs/live-tail.rst:72
msgid ""
"To use Live Tail filtering to verify your Kubernetes integration worked, "
"follow these steps:"
msgstr ""

#: ../../logs/live-tail.rst:74 ../../logs/live-tail.rst:112
msgid ""
"In Log Observer, click the navigation bar menu, select the "
":menuselection:`time picker`, then select :menuselection:`Live Tail` from"
" the time picker drop-down list."
msgstr ""

#: ../../logs/live-tail.rst:77
msgid "To add a filter, in the navigation bar click :guilabel:`Add Filter`."
msgstr ""

#: ../../logs/live-tail.rst:79
msgid "Select the filter type you want to use:"
msgstr ""

#: ../../logs/live-tail.rst:81
msgid "To filter by keywords, click the :guilabel:`Keywords` tab."
msgstr ""

#: ../../logs/live-tail.rst:83
msgid "To filter by fields in the log records, click the :guilabel:`Fields` tab."
msgstr ""

#: ../../logs/live-tail.rst:85
msgid ""
"In the :guilabel:`Find` text box, type the keyword or field that you want"
" to filter on, then press Enter to filter the logs as they stream into "
"the Live Tail display."
msgstr ""

#: ../../logs/live-tail.rst:88
msgid ""
"To filter for minimum or maximum values in a numeric field, enter a range"
" in the :guilabel:`Min` and :guilabel:`Max` text boxes."
msgstr ""

#: ../../logs/live-tail.rst:91
msgid ""
"For example, if you add a filter for the log record field "
":monospace:`K8s.container.name`, you see this field name in all the "
"records in the display. If you don't see the field, then you know that "
"your integration might have problems."
msgstr ""

#: ../../logs/live-tail.rst:95
msgid "Adding filters helps you find log records for a specific integration."
msgstr ""

#: ../../logs/live-tail.rst:101
msgid "Example: Verify an integration with Live Tail keyword highlighting"
msgstr ""

#: ../../logs/live-tail.rst:103
msgid ""
"Live Tail highlighting helps you filter logs using keywords. You can "
"specify up to nine keywords at a time, and Live Tail displays each "
"keyword it finds with a unique color."
msgstr ""

#: ../../logs/live-tail.rst:107
msgid ""
"If you highlight nine keywords, you have to remove a keyword to add "
"another one."
msgstr ""

#: ../../logs/live-tail.rst:110
msgid "To highlight keywords in log records, follow these steps:"
msgstr ""

#: ../../logs/live-tail.rst:114
msgid ""
"In the navigation bar, type up to nine keywords in the :guilabel:`Enter "
"keyword` text box, then press Enter. Live Tail displays each keyword it "
"finds with a unique color."
msgstr ""

#: ../../logs/lo-connect-landing.rst:-1
msgid ""
"The Log Observer Connect landing page lists and describes all "
"capabilities. Investigate logs in context with metrics and traces in "
"Splunk Log Observer Connect."
msgstr ""

#: ../../logs/lo-connect-landing.rst:5
msgid "Splunk Log Observer Connect"
msgstr ""

#: ../../logs/lo-connect-landing.rst:33
msgid ":ref:`logs-intro-logconnect`"
msgstr ""

#: ../../logs/lo-connect-landing.rst:35
msgid ":ref:`logs-scp`"
msgstr ""

#: ../../logs/lo-connect-landing.rst:37
msgid ":ref:`logs-set-up-logconnect`"
msgstr ""

#: ../../logs/lo-connect-landing.rst:39
msgid ":ref:`logs-LOconnect-troubleshoot`"
msgstr ""

#: ../../logs/lo-connect-landing.rst:41
msgid ":ref:`logs-LOconnect-scenario`"
msgstr ""

#: ../../logs/lo-connect-landing.rst:45 ../../logs/log-observer-landing.rst:46
msgid ":ref:`logs-queries`"
msgstr ""

#: ../../logs/lo-connect-landing.rst:51 ../../logs/log-observer-landing.rst:52
msgid ":ref:`logs-alias`"
msgstr ""

#: ../../logs/lo-connect-landing.rst:53
msgid ":ref:`logs-individual-log-connect`"
msgstr ""

#: ../../logs/lo-connect-landing.rst:55 ../../logs/log-observer-landing.rst:56
msgid ":ref:`logs-message-field`"
msgstr ""

#: ../../logs/lo-connect-landing.rst:61 ../../logs/log-observer-landing.rst:64
msgid ":ref:`logs-logviews`"
msgstr ""

#: ../../logs/lo-connect-landing.rst:63 ../../logs/log-observer-landing.rst:74
msgid ":ref:`logs-timestamp`"
msgstr ""

#: ../../logs/lo-connect-landing.rst:65
msgid ":ref:`lo-connect-limits`"
msgstr ""

#: ../../logs/lo-connect-landing.rst:68
msgid ""
"If you do not have Log Observer Connect and instead use Log Observer, see"
" :ref:`log-observer-landing`."
msgstr ""

#: ../../logs/lo-connect-limits.rst:5
msgid "Log Observer Connect limits"
msgstr ""

#: ../../logs/lo-connect-limits.rst:10
msgid ""
"This page documents Splunk Log Observer Connect service limits and "
"behavior. System protection limits are meant to allow for stability and "
"availability of multi-tenant systems and are subject to fine-tuning and "
"change without notice."
msgstr ""

#: ../../logs/lo-connect-limits.rst:14
msgid "Log Observer Connect search query limits"
msgstr ""

#: ../../logs/lo-connect-limits.rst:15
msgid "The following table lists Log Observer Connect's search query limits:"
msgstr ""

#: ../../logs/lo-connect-limits.rst:27
msgid "Maximum number of logs processed for fields summary"
msgstr ""

#: ../../logs/lo-connect-limits.rst:40
msgid "Maximum number of logs processed for the fields summary"
msgstr ""

#: ../../logs/lo-connect-limits.rst:42
msgid ""
"The Log Observer Connect UI displays a summary of fields and their value "
"distribution. By default, it processes the most recent 150,0000 events to"
" generate this view."
msgstr ""

#: ../../logs/lo-connect-limits.rst:51
msgid "Other limits"
msgstr ""

#: ../../logs/lo-connect-limits.rst:52
msgid ""
"Each Log Observer Connect user is also subject to the limits of their "
"Splunk platform role. A user can only access Splunk platform resources "
"that their Splunk platform role allows them to access. See :new-"
"page:`About configuring role-based user access "
"<https://docs.splunk.com/Documentation/Splunk/9.0.2/Security/Aboutusersandroles#Set_permission_granularity_with_custom_roles>`"
" for more information."
msgstr ""

#: ../../logs/log-observer-landing.rst:-1
msgid ""
"The Log Observer landing page lists and describes all capabilities. "
"Investigate logs in context with metrics and traces in Splunk Log "
"Observer."
msgstr ""

#: ../../logs/log-observer-landing.rst:5
msgid "Splunk Log Observer"
msgstr ""

#: ../../logs/log-observer-landing.rst:38
msgid ":ref:`get-started-logs`"
msgstr ""

#: ../../logs/log-observer-landing.rst:40
msgid ":ref:`logs-logs`"
msgstr ""

#: ../../logs/log-observer-landing.rst:66
msgid ":ref:`logs-pipeline`"
msgstr ""

#: ../../logs/log-observer-landing.rst:76
msgid ":ref:`logs-limits`"
msgstr ""

#: ../../logs/log-observer-landing.rst:79
msgid ""
"If you do not have a Log Observer entitlement and instead use Log "
"Observer Connect, see :ref:`lo-connect-landing`."
msgstr ""

#: ../../logs/logs.rst:-1
msgid ""
"Connect Splunk Observability Cloud to your data sources. Set up Log "
"Observer to investigate logs in context with metrics and traces."
msgstr ""

#: ../../logs/logs.rst:5
msgid "Set up Log Observer"
msgstr ""

#: ../../logs/logs.rst:14
msgid ""
"Complete the instructions on this page if you have a Log Observer "
"entitlement in Observability Cloud. If you don't have a Log Observer "
"entitlement in Observability Cloud, see :ref:`logs-intro-logconnect` to "
"set up the integration and begin using Log Observer to query your Splunk "
"platform logs."
msgstr ""

#: ../../logs/logs.rst:16
msgid ""
"By default, Log Observer indexes and stores all logs data that you send "
"to Observability Cloud unless you choose to archive some of your logs "
"data in Amazon S3 buckets. See :ref:`logs-infinite` to learn how to "
"archive logs until you want to index and analyze them in Log Observer. If"
" you use Log Observer Connect, your logs data remains in your Splunk "
"platform instance and is never stored in Log Observer or Observability "
"Cloud."
msgstr ""

#: ../../logs/logs.rst:19
msgid "What type of data is supported?"
msgstr ""

#: ../../logs/logs.rst:20
msgid "Splunk Log Observer supports unstructured log data at ingest."
msgstr ""

#: ../../logs/logs.rst:25
msgid "Before setting up Log Observer, you must meet the following criteria:"
msgstr ""

#: ../../logs/logs.rst:27
msgid ""
"Your Observability Cloud organization must be provisioned with an "
"entitlement for Log Observer."
msgstr ""

#: ../../logs/logs.rst:28
msgid ""
"You must be an administrator in an Observability Cloud organization to "
"set up integrations."
msgstr ""

#: ../../logs/logs.rst:32
msgid "Start using Log Observer"
msgstr ""

#: ../../logs/logs.rst:33
msgid ""
"You can use Observability Cloud guided setups to send logs to Log "
"Observer from your hosts, containers, and cloud providers. Use the "
":ref:`Splunk Distribution of OpenTelemetry Collector <otel-intro>` to "
"capture logs from your resources and applications. Decide whether you "
"want to see logs from each data source, only one, or any combination of "
"data sources. The more complete your log collection in Log Observer, the "
"more effective your use of Log Observer can be for troubleshooting your "
"entire environment using logs. You can complete step 1, step 2, or both "
"in the following list, depending on which logs you want to see."
msgstr ""

#: ../../logs/logs.rst:35
msgid "To start using Log Observer, complete the following tasks:"
msgstr ""

#: ../../logs/logs.rst:37
msgid ":ref:`Collect logs from your hosts and containers <hosts-containers>`"
msgstr ""

#: ../../logs/logs.rst:39
msgid ":ref:`Collect logs from your cloud providers <cloud-providers>`"
msgstr ""

#: ../../logs/logs.rst:41
msgid ":ref:`Filter and aggregate your data in Log Observer <work-with-data>`"
msgstr ""

#: ../../logs/logs.rst:43
msgid ":ref:`Ensure the severity key is correctly mapped <severity-key>`"
msgstr ""

#: ../../logs/logs.rst:48
msgid "Collect logs from your hosts and containers"
msgstr ""

#: ../../logs/logs.rst:49
msgid ""
"To send logs from your hosts and containers to Log Observer, follow these"
" instructions:"
msgstr ""

#: ../../logs/logs.rst:51 ../../logs/logs.rst:70
msgid "Log in to Splunk Observability Cloud."
msgstr ""

#: ../../logs/logs.rst:53
msgid ""
"In the left navigation menu, select :menuselection:`Data Management` to "
"open the Integrate Your Data page."
msgstr ""

#: ../../logs/logs.rst:55
msgid ""
"On the :strong:`Integrate Your Data` page in Observability Cloud, select "
"the tile for the platform you want to import logs from. You can select "
"Windows, Kubernetes, or Linux. The guided setup for your platform "
"appears."
msgstr ""

#: ../../logs/logs.rst:57 ../../logs/logs.rst:78
msgid ""
"Follow the instructions in the guided setup then see :ref:`work-with-"
"data`."
msgstr ""

#: ../../logs/logs.rst:59
msgid ""
"After you see data coming into Log Observer from your data source, you "
"can send logs from another data source or continue analyzing logs from "
"the platform you have just set up."
msgstr ""

#: ../../logs/logs.rst:64
msgid "Collect logs from your cloud providers"
msgstr ""

#: ../../logs/logs.rst:67
msgid "Amazon Web Services"
msgstr ""

#: ../../logs/logs.rst:68
msgid ""
"To send logs from Amazon Web Services to Log Observer, follow these "
"instructions:"
msgstr ""

#: ../../logs/logs.rst:72
msgid ""
"In the left navigation menu, select :menuselection:`Data Management` to "
"display the Integrate Your Data page."
msgstr ""

#: ../../logs/logs.rst:74
msgid "Select :guilabel:`Add Integration`."
msgstr ""

#: ../../logs/logs.rst:76
msgid ""
"In the :guilabel:`Cloud Integrations` section, select the the Amazon Web "
"Services tile."
msgstr ""

#: ../../logs/logs.rst:80
msgid ""
"For more information about setting up an AWS connection, see :ref:`aws-"
"logs` and :ref:`aws-cloudformation`."
msgstr ""

#: ../../logs/logs.rst:83
msgid "Google Cloud Platform"
msgstr ""

#: ../../logs/logs.rst:84
msgid ""
"To send logs from Google Cloud Platform to Log Observer, follow the "
"instructions in :ref:`ingest-gcp-log-data` then see :ref:`work-with-"
"data`."
msgstr ""

#: ../../logs/logs.rst:87
msgid "Microsoft Azure"
msgstr ""

#: ../../logs/logs.rst:88
msgid ""
"To send logs from Microsoft Azure to Log Observer, follow the "
"instructions in :ref:`ingest-azure-log-data` then see :ref:`work-with-"
"data`."
msgstr ""

#: ../../logs/logs.rst:90
msgid ""
"After you see data coming into Log Observer from your data source, you "
"can send logs from another data source or continue analyzing logs from "
"the cloud provider you have just set up."
msgstr ""

#: ../../logs/logs.rst:94
msgid ""
"If you already have existing Fluentd or Fluent Bit deployments, you can "
"configure them to send logs to Log Observer. However, it is important to "
"note that the following are true when using Fluentd or Fluent Bit:"
msgstr ""

#: ../../logs/logs.rst:96
msgid ""
"Logs captured by your own Fluentd or Fluent Bit agents do not include the"
" resource metadata that automatically links log data to other related "
"sources available within APM and Infrastructure Monitoring."
msgstr ""

#: ../../logs/logs.rst:98
msgid ""
"Although there are multiple ways to send log data to Log Observer, Splunk"
" only provides direct support for the Splunk distribution of "
"OpenTelemetry Collector."
msgstr ""

#: ../../logs/logs.rst:100
msgid ""
"If you still want to use Fluentd to send logs to Log Observer, see "
":ref:`Configure Fluentd to send logs <fluentd>`."
msgstr ""

#: ../../logs/logs.rst:105
msgid "Filter and aggregate your data in Log Observer"
msgstr ""

#: ../../logs/logs.rst:106
msgid ""
"After you have collected some logs, use filters and aggregation to "
"efficiently navigate your logs in Log Observer. You can verify that Log "
"Observer is correctly processing and indexing your logs by filtering and "
"aggregating your log data."
msgstr ""

#: ../../logs/logs.rst:108
msgid ""
"You can use the Log Observer interface to filter your logs based on "
"keywords or fields. To filter your data, follow these steps:"
msgstr ""

#: ../../logs/logs.rst:110
msgid "Select :strong:`Add Filter`."
msgstr ""

#: ../../logs/logs.rst:112
msgid ""
"To find logs containing a keyword, select the :strong:`Keyword` tab and "
"enter a keyword."
msgstr ""

#: ../../logs/logs.rst:114
msgid ""
"To find logs containing a specific field, select the :strong:`Fields` tab"
" and enter a field in :strong:`Find a field` then select it from the "
"list. If helpful, you can enter a value for the specified field."
msgstr ""

#: ../../logs/logs.rst:116
msgid ""
"To display only results that include the keywords, fields, or field "
"values you entered, select the equal sign (=) next to the appropriate "
"entry. To display only results that exclude the keywords, fields, or "
"field values you entered, select the not equal sign (!=) next to the "
"appropriate entry."
msgstr ""

#: ../../logs/logs.rst:118
msgid ""
"The resulting logs appear in the Logs table. You can add more filters, "
"enable and disable existing filters, and select individual logs to learn "
"more."
msgstr ""

#: ../../logs/logs.rst:120
msgid ""
"Perform aggregations on logs to visualize problems in a histogram that "
"shows averages, sums, and other statistics related to logs. Aggregations "
"group related data by one field and then perform statistical calculation "
"on other fields. Find the aggregations controls in the control bar at the"
" top of the Log Observer UI. The default aggregation shows all logs "
"grouped by severity."
msgstr ""

#: ../../logs/logs.rst:122
msgid "See :ref:`logs-aggregations` to learn how to perform more aggregations."
msgstr ""

#: ../../logs/logs.rst:127
msgid "Ensure severity key is correctly mapped"
msgstr ""

#: ../../logs/logs.rst:128
msgid ""
"The severity key is a field that all logs contain. It has the values "
"``Debug``, ``Error``, ``Info``, ``Unknown``, and ``Warning``. Because the"
" ``severity`` field in many logs is called ``level``, Log Observer "
"automatically remaps the log field ``level`` to ``severity``."
msgstr ""

#: ../../logs/logs.rst:130
msgid ""
"If your logs call the ``severity`` key by a different name, that's okay. "
"To ensure that Log Observer can read your field, transform your field "
"name to ``severity`` using a Field Copy Processor. See :ref:`field-copy-"
"processors` to learn how."
msgstr ""

#: ../../logs/logs.rst:135
msgid "Configure Fluentd to send logs"
msgstr ""

#: ../../logs/logs.rst:136
msgid ""
"If you already have Fluentd running in your environment, you can "
"reconfigure it to send logs to an additional output. To send logs to "
"Splunk Observability Cloud in addition to your current system, follow "
"these steps:"
msgstr ""

#: ../../logs/logs.rst:140
msgid "Make sure that you have the HEC plugin for Fluentd installed."
msgstr ""

#: ../../logs/logs.rst
msgid ":strong:`Option A`"
msgstr ""

#: ../../logs/logs.rst
msgid ""
"Install the plugin and rebuild the Fluentd using the instructions in "
":new-page:`fluent-plugin-splunk-hec <https://github.com/splunk/fluent-"
"plugin-splunk-hec#installation>`."
msgstr ""

#: ../../logs/logs.rst
msgid ":strong:`Option B`"
msgstr ""

#: ../../logs/logs.rst
msgid ""
"Use an existing Fluentd docker image with HEC plugin included. To get "
"this image, enter"
msgstr ""

#: ../../logs/logs.rst
msgid "`docker pull splunk/fluentd-hec`."
msgstr ""

#: ../../logs/logs.rst
msgid ""
"To learn more, see :new-page:`Fluentd docker image with HEC plugin "
"included <https://hub.docker.com/r/splunk/fluentd-hec>`."
msgstr ""

#: ../../logs/logs.rst:151
msgid ""
"Add HEC output. Change your Fluentd configuration by adding another "
"output section. The new HEC output section points to Splunk’s SignalFx "
"Observability ingest endpoint."
msgstr ""

#: ../../logs/logs.rst:155
msgid "For example, if you have one output to elasticsearch, follow these steps:"
msgstr ""

#: ../../logs/logs.rst:157
msgid "Change ``type`` from ``@elasticsearch`` to ``@copy`` in the match section."
msgstr ""

#: ../../logs/logs.rst:158
msgid "Put ``elasticsearch`` into the ``<store>`` block."
msgstr ""

#: ../../logs/logs.rst:159
msgid "Add another ``<store>`` block for HEC output."
msgstr ""

#: ../../logs/logs.rst:162
msgid "The following is a sample of output to ``@elasticsearch``:"
msgstr ""

#: ../../logs/logs.rst:174
msgid "Change the ``@elasticsearch`` output to the following:"
msgstr ""

#: ../../logs/logs.rst:199
msgid ""
"In the new ``<store>`` section for splunk_hec, provide at least the "
"following fields:"
msgstr ""

#: ../../logs/logs.rst:201
msgid ""
"``hec_host`` - Set the HEC ingest host (for example, "
"``ingest.us1.signalfx.com hec_port``) to 443."
msgstr ""

#: ../../logs/logs.rst:203
msgid "``hec_token`` - Provide the SignalFx access token."
msgstr ""

#: ../../logs/logs.rst:205
msgid "Specify the following parameters:"
msgstr ""

#: ../../logs/logs.rst:207
msgid ""
"``sourcetype_key`` or ``sourcetype`` - Defines source type of logs by "
"using a particular log field or static value"
msgstr ""

#: ../../logs/logs.rst:209
msgid ""
"``source_key`` or ``source`` - Defines source of logs by using a "
"particular log field or static value"
msgstr ""

#: ../../logs/logs.rst:211
msgid ""
"Set up a buffer configuration for HEC output. The following is an example"
" using memory buffer:"
msgstr ""

#: ../../logs/logs.rst:226
msgid ""
"For more details on buffer configuration, see :new-page:`About buffer "
"<https://github.com/splunk/fluent-plugin-splunk-hec#about-buffer>`."
msgstr ""

#: ../../logs/logs.rst:228
msgid ""
"See :new-page:`HEC exporter documentation <https://github.com/splunk"
"/fluent-plugin-splunk-hec#parameters-for-both-splunk_hec-and-"
"splunk_ingest_api>` to learn about other optional fields."
msgstr ""

#: ../../logs/logs-individual-log-connect.rst:-1
msgid ""
"View the contents of an individual log, then create a field extraction to"
" drill down further. See message, error, span ID, trace ID, and other "
"fields."
msgstr ""

#: ../../logs/logs-individual-log-connect.rst:5
msgid "View individual log details"
msgstr ""

#: ../../logs/logs-individual-log-connect.rst:11
msgid ""
"After you find log records that contain a specific area, view the "
"contents of an individual record to get a precise view of the data "
"related to the problem."
msgstr ""

#: ../../logs/logs-individual-log-connect.rst:15
msgid "To view the contents of an individual log record, follow these steps:"
msgstr ""

#: ../../logs/logs-individual-log-connect.rst:17
msgid ""
"Select a log record line in the Logs table to display the log details "
"panel. This panel displays the entire record in JSON format as well as a "
"table of each field and its value."
msgstr ""

#: ../../logs/logs-individual-log-connect.rst:20
msgid ""
"To do more with a particular field in the table, select the field value. "
"Log Observer displays a drop-down list with 5 options:"
msgstr ""

#: ../../logs/logviews.rst:-1
msgid ""
"Add logs data to Observability Cloud dashboards without turning your logs"
" into metrics first. Align log views, log timeline charts, and metrics "
"charts on one dashboard."
msgstr ""

#: ../../logs/logviews.rst:5
msgid "Add logs data to Splunk Observability Cloud dashboards"
msgstr ""

#: ../../logs/logviews.rst:10
msgid ""
"On a dashboard, metrics charts show what changed in your systems and when"
" the problem started. Logs data on the same dashboard shows you in detail"
" what is happening and why. All the data you add to a dashboard respond "
"to the same time selection and other dashboard filters, allowing you to "
"drill down to the source of the problem faster."
msgstr ""

#: ../../logs/logviews.rst:12
msgid "There are two ways to visualize logs data in dashboards:"
msgstr ""

#: ../../logs/logviews.rst:14
msgid ""
"Log view: Displays a table showing log records in chronological order for"
" the duration of the period selected in the time picker"
msgstr ""

#: ../../logs/logviews.rst:16
msgid ""
"Log timeline: Displays a histogram chart of logged events over time "
"grouped by fields and values of your choice"
msgstr ""

#: ../../logs/logviews.rst:18
msgid ""
"Both types of logs charts automatically update to dashboard filters. "
"Filter and aggregate logs in Log Observer before creating a log view or "
"log timeline chart."
msgstr ""

#: ../../logs/logviews.rst:20
msgid ""
"Log Observer Connect customers can only create logs charts in dashboards "
"if each Log Observer Connect connection name is unique. If you create a "
"log timeline chart that does not function properly, reach out to your Log"
" Observer Connect administrator to see if each Log Observer Connect "
"connection name is unique."
msgstr ""

#: ../../logs/logviews.rst:25
msgid "Add logs data to a dashboard"
msgstr ""

#: ../../logs/logviews.rst:26
msgid ""
"To add a log view or log timeline chart on a dashboard, follow these "
"steps:"
msgstr ""

#: ../../logs/logviews.rst:28
msgid ""
"Log into Log Observer and create a query. To learn how, see :ref:`logs-"
"queries`."
msgstr ""

#: ../../logs/logviews.rst:30
msgid "In the :strong:`Save` menu, select :strong:`Save to dashboard`."
msgstr ""

#: ../../logs/logviews.rst:32
msgid ""
"Give your log view a name and optionally a description, then select a "
"dashboard."
msgstr ""

#: ../../logs/logviews.rst:34
msgid ""
"In :strong:`Chart type`, select :strong:`Log timeline` or :strong:`Log "
"view`, then select :strong:`Save`. Or, to see your new log view on its "
"dashboard, select :strong:`Save and go to dashboard`."
msgstr ""

#: ../../logs/logviews.rst:36
msgid ""
"You can now see your new log view along with all other charts on the same"
" dashboard."
msgstr ""

#: ../../logs/logviews.rst:39
msgid "Modify your logs chart from the dashboard"
msgstr ""

#: ../../logs/logviews.rst:40
msgid ""
"You cannot directly edit a logs chart from the dashboard. For example, "
"you cannot edit the column headings or data on your log view chart from "
"the dashboard. You can delete a log view entirely using the "
":strong:`More` menu. See :ref:`Chart actions <chart-actions>` to learn "
"more."
msgstr ""

#: ../../logs/logviews.rst:42
msgid ""
"Log view and log timeline charts respond to any filter or time selection "
"that you make on the dashboard. For example, when you adjust the "
":strong:`Time` field in the dashboard global control bar, logs charts "
"update in unison with all other charts on the dashboard."
msgstr ""

#: ../../logs/logviews.rst:44
msgid ""
"You can rearrange the columns in a log view by dragging and dropping "
"column headers to a preferred order. You can sort rows in your log view "
"by selecting the column header that you want to sort by."
msgstr ""

#: ../../logs/logviews.rst:50
msgid "Chart actions"
msgstr ""

#: ../../logs/logviews.rst:51
msgid ""
"You can take 7 actions on your logs chart from its dashboard. Select the "
":strong:`More` menu on your logs chart, then select one of the following "
"options:"
msgstr ""

#: ../../logs/logviews.rst:53
msgid "View in Log Observer"
msgstr ""

#: ../../logs/logviews.rst:55
msgid "Copy"
msgstr ""

#: ../../logs/logviews.rst:57
msgid "Info"
msgstr ""

#: ../../logs/logviews.rst:59
msgid "Download chart as image"
msgstr ""

#: ../../logs/logviews.rst:61
msgid "Troubleshoot from this Time Window (APM)"
msgstr ""

#: ../../logs/logviews.rst:63
msgid "Troubleshoot from this Time Window (RUM)"
msgstr ""

#: ../../logs/logviews.rst:65
msgid "Delete"
msgstr ""

#: ../../logs/logviews.rst:67
msgid ""
"You can only edit the contents of your logs chart by updating the query "
"you derived it from in Log Observer. Select :strong:`View in Log "
"Observer` to see and edit your logs chart in Log Observer. In Log "
"Observer, you can update the logs chart's filters, including field "
"aliases. See :ref:`Align logs charts with metrics charts on the same "
"dashboard <field-aliasing>` to learn more."
msgstr ""

#: ../../logs/logviews.rst:69
msgid ""
"For more information on the actions you can take from the :strong:`Chart "
"actions` menu, see :ref:`work-with-charts`."
msgstr ""

#: ../../logs/logviews.rst:74
msgid "Align logs charts with metrics charts on the same dashboard"
msgstr ""

#: ../../logs/logviews.rst:75
msgid ""
"To maneuver seamlessly on your dashboard, logs fields and corresponding "
"metrics fields should use the same field names. You can ensure that field"
" names match by aliasing logs fields when field names do not align."
msgstr ""

#: ../../logs/logviews.rst:77
msgid "To align logs data with metrics data, follow these steps:"
msgstr ""

#: ../../logs/logviews.rst:79
msgid ""
"On the dashboard you are using to determine the source of a problem, take"
" note of the field names of interest on your metrics charts."
msgstr ""

#: ../../logs/logviews.rst:81
msgid ""
"In Log Observer, check whether the corresponding logs fields use the same"
" field names. If they do not match, create a field alias for the logs "
"field using the same field name that your metrics charts use. See :ref"
":`logs-alias` to learn how."
msgstr ""

#: ../../logs/logviews.rst:83
msgid ""
"Go back to your dashboard and filter by the field name again using the "
"new alias you created in the previous step."
msgstr ""

#: ../../logs/logviews.rst:85
msgid ""
"Follow the steps in :ref:`create-logviews-chart` to save your new query "
"as a chart."
msgstr ""

#: ../../logs/logviews.rst:87
msgid ""
"Now you can efficiently cross reference data in your logs chart with data"
" in any other charts on the same dashboard. Logs fields that correspond "
"to metrics fields on the same dashboard now use the same field name, so "
"you can drill down to the problem faster. Field aliasing does not rename "
"or remove your original logs field name. When you alias a logs field, you"
" can search for it by its original name or by any of its aliases."
msgstr ""

#: ../../logs/message-field.rst:-1
msgid ""
"Display the message field from your logs in an easy-to-access flyout in "
"each individual log record."
msgstr ""

#: ../../logs/message-field.rst:5
msgid "Display a field separately in the log details flyout"
msgstr ""

#: ../../logs/message-field.rst:10
msgid ""
"The log details flyout in Log Observer always displays the ``message`` "
"field in a standalone section called :strong:`MESSAGE` at the top of the "
"log details flyout."
msgstr ""

#: ../../logs/message-field.rst:16
msgid ""
"Your team can choose to display any field of your choice in the "
":strong:`MESSAGE` section. To display a field of your choice separately, "
"alias the desired field to the ``message`` field. See :ref:`logs-alias` "
"to learn how."
msgstr ""

#: ../../logs/message-field.rst:18
msgid ""
"For example, say your team most frequently uses the ``summary`` field. "
"Add an alias for the ``summary`` field called ``message``. The "
"``summary`` field still exists but is also known as ``message`` and "
"appears in the :strong:`MESSAGE` section of the log details flyout."
msgstr ""

#: ../../logs/metricization.rst:-1
msgid ""
"Log metricization rules derive metrics from logs. Show an aggregate count"
" of logs grouped by a dimension. Embed logs data in charts, dashboards, "
"and detectors."
msgstr ""

#: ../../logs/metricization.rst:5
msgid "Create metrics from your logs with log metricization rules"
msgstr ""

#: ../../logs/metricization.rst:10
msgid ""
"Only customers with a Splunk Log Observer entitlement in Splunk "
"Observability Cloud can create log metricization rules. If you do not "
"have a Log Observer entitlement and are using Splunk Log Observer Connect"
" instead, see :ref:`logs-intro-logconnect` to learn what you can do with "
"the Splunk Enterprise integration."
msgstr ""

#: ../../logs/metricization.rst:12
msgid ""
"Log metricization rules allow you to create a log-derived metric showing "
"an aggregate count of logs grouped by the dimension of your choice. While"
" Log Observer visual analysis allows you to dynamically view aggregate "
"metrics in the context of your query, log metricization rules allow you "
"to embed metrics from log data in charts, dashboards, and detectors. Log "
"metricization rules enable you to see trends in your full logs data set "
"without paying to index all of your logs data."
msgstr ""

#: ../../logs/metricization.rst:22
msgid "Infinite logging rules"
msgstr ""

#: ../../logs/metricization.rst:24
msgid ""
"Log Observer indexes your logs data only after executing all pipeline "
"management rules. When you metricize then archive a set of logs, "
"metricized logs count against your ingest capacity but not against your "
"indexing capacity. Like any other metric, a metric derived from log "
"metricization rules counts toward your metrics quota per your contract. "
"For more information, see :ref:`logs-pipeline-sequence`."
msgstr ""

#: ../../logs/metricization.rst:26
msgid ""
"All pipeline management rules, including log metricization rules, apply "
"only to logs that are sent to Splunk Observability Cloud.  You can't "
"apply log metricization rules, or any pipeline management rules, to logs "
"viewed in Log Observer Connect because logs are not ingested into "
"Observability Cloud. Log Observer Connect lets users view and analyze "
"Splunk Platform logs but can't transform them."
msgstr ""

#: ../../logs/metricization.rst:29
msgid "Create log metricization rules"
msgstr ""

#: ../../logs/metricization.rst:30
msgid "There are two ways to create log metricization rules:"
msgstr ""

#: ../../logs/metricization.rst:32
msgid ""
":ref:`Create a log metricization rule from the logs pipeline "
"<metricization-rule-from-pipeline>`"
msgstr ""

#: ../../logs/metricization.rst:33
msgid ""
":ref:`Create a log metricization rule in the context of a Log Observer "
"query <metricization-rule-from-Log-Observer-query>`"
msgstr ""

#: ../../logs/metricization.rst:38
msgid "Create a log metricization rule from the logs pipeline"
msgstr ""

#: ../../logs/metricization.rst:40
msgid ""
"To create a new log metricization rule from scratch in the logs pipeline,"
" follow these steps:"
msgstr ""

#: ../../logs/metricization.rst:44
msgid "Click :guilabel:`New Metricization Rule`."
msgstr ""

#: ../../logs/metricization.rst:46
msgid ""
"Define a matching condition. Only matching logs will be included in the "
"chart resulting from your metricization rule."
msgstr ""

#: ../../logs/metricization.rst:48
msgid ""
"To configure a metric, perform a Log Observer aggregation query. Select a"
" function, an aggregate, and a dimension for this query. You can choose "
"from the following functions: :guilabel:`Count`, :guilabel:`AVG`, "
":guilabel:`MAX`, :guilabel:`MIN`, and :guilabel:`SUM`. The default "
"function is :guilabel:`Count`. The default aggregate for Log Observer is "
":guilabel:`All(*)`, and the default dimension is :guilabel:`severity`. "
"Log Observer Connect has no default aggregation. To change the dimension "
"of the aggregation, select another dimension in the :guilabel:`Group by` "
"field. To See :ref:`logs-aggregations` for a thorough explanation of "
"aggregation queries."
msgstr ""

#: ../../logs/metricization.rst:50
msgid ""
"Next, select a target field by which you want to aggregate logs. For "
"example, you can choose :guilabel:`services` as your target field, then "
"group logs by :guilabel:`status`. Fields with \"#\", such as "
":guilabel:`amount`, require a numerical value to aggregate logs."
msgstr ""

#: ../../logs/metricization.rst:54
msgid ""
"Review your metric time series (MTS) summary to see how your "
"metricization could affect your subscription usage. You can optionally "
"select an ingest token to limit the MTS count."
msgstr ""

#: ../../logs/metricization.rst:58
msgid ""
"Give your metric a name. The name defaults to the function and target "
"fields."
msgstr ""

#: ../../logs/metricization.rst:60
msgid ""
"You can optionally change the Metric Type to :guilabel:`Gauge`, "
":guilabel:`Counter`, or :guilabel:`Cumulative counter`."
msgstr ""

#: ../../logs/metricization.rst:62
msgid "Give your rule a name and description."
msgstr ""

#: ../../logs/metricization.rst:64
msgid ""
"Review your configuration, then click :guilabel:`Save`. Your rule appears"
" in the list of Metricization Rules on the Logs Pipeline Management page."
" Click the name of your rule to view a summary of the rule. To view the "
"output of your rule, click :guilabel:`view your new metric in a chart`. "
"This takes you to chart builder populated with your new metric. In less "
"than 60 seconds, you will see metrics reported within the chart."
msgstr ""

#: ../../logs/metricization.rst:66
msgid ""
"While still in chart builder, click :guilabel:`Save As` to save your new "
"metric as a chart. You can then embed it on a new or existing dashboard."
msgstr ""

#: ../../logs/metricization.rst:71
msgid "Create a log metricization rule in the context of a Log Observer query"
msgstr ""

#: ../../logs/metricization.rst:73
msgid ""
"Often, you might notice the potential value of an existing query and "
"decide to create a log metricization rule based on that query. You can "
"quickly launch the creation of a new metricization rule from a Log "
"Observer query."
msgstr ""

#: ../../logs/metricization.rst:75
msgid ""
"To create a new log metricization rule in the context of an existing "
"search query, follow these steps:"
msgstr ""

#: ../../logs/metricization.rst:77
msgid "In the navigation menu, go to :guilabel:`Log Observer`."
msgstr ""

#: ../../logs/metricization.rst:79
msgid ""
"Create a query that aggregates logs. See :ref:`logs-aggregations` to "
"learn how."
msgstr ""

#: ../../logs/metricization.rst:81
msgid ""
"In the :guilabel:`Save` menu, select :guilabel:`Save as Metric`. This "
"takes you to the Configure Metric page in Logs Pipeline Management."
msgstr ""

#: ../../logs/metricization.rst:83
msgid ""
"Go to step 3 in :ref:`Create a log metricization rule from the logs "
"pipeline <metricization-rule-from-pipeline>` and complete the "
"instructions."
msgstr ""

#: ../../logs/metricization.rst:86
msgid "Log metricization rules limits"
msgstr ""

#: ../../logs/metricization.rst:87
msgid "An organization can create a total of 128 log metricization rules."
msgstr ""

#: ../../logs/pipeline.rst:-1
msgid ""
"Manage the logs pipeline with log processing rules, log metricization "
"rules, and Infinite Logging rules. Customize your pipeline."
msgstr ""

#: ../../logs/pipeline.rst:5
msgid "Manage the logs pipeline"
msgstr ""

#: ../../logs/pipeline.rst:10
msgid ""
"Only customers with a Splunk Log Observer entitlement in Splunk "
"Observability Cloud can manage the logs pipeline. If you do not have a "
"Log Observer entitlement and are using Splunk Log Observer Connect "
"instead, see :ref:`logs-intro-logconnect` to learn what you can do with "
"the Splunk Enterprise integration."
msgstr ""

#: ../../logs/pipeline.rst:12
msgid ""
"Add value to your raw logs by customizing your pipeline. The pipeline is "
"a set of rules that execute sequentially."
msgstr ""

#: ../../logs/pipeline.rst:14
msgid "Observability Cloud lets you create three types of pipeline rules:"
msgstr ""

#: ../../logs/pipeline.rst:16
msgid ""
":ref:`Log processing rules <logs-processors>` transform your data or a "
"subset of your data as it arrives in Observability Cloud."
msgstr ""

#: ../../logs/pipeline.rst:17
msgid ""
":ref:`Log metricization rules <logs-metricization>` let you create charts"
" to see trends in your logs."
msgstr ""

#: ../../logs/pipeline.rst:18
msgid ""
":ref:`Infinite Logging rules <logs-infinite>` archive unindexed logs in "
"Amazon S3 buckets for potential future use."
msgstr ""

#: ../../logs/pipeline.rst:23
msgid "Sequence of logs pipeline rules"
msgstr ""

#: ../../logs/pipeline.rst:30
msgid "All Infinite Logging rules"
msgstr ""

#: ../../logs/pipeline.rst:32
msgid ""
"Adjust the order of custom rules by dragging and dropping their placement"
" within their rule category. Log Observer indexes logs only after all "
"three types of pipeline rules are executed. Any logs that you archive "
"through Infinite Logging rules do not count toward your indexing "
"capacity."
msgstr ""

#: ../../logs/pipeline.rst:34
msgid ""
"Because log processing rules execute first, you can create field "
"extraction rules, then use the resulting fields in log metricization "
"rules or Infinite Logging rules or both. For example, say you want to "
"archive and not index all logs that contain the values ‘START’, ‘RETRY’, "
"‘FAIL’, and ‘SUCCESS’ in the :guilabel:`message` field, which also "
"contains other information. Without any processing, you might need to "
"create a rule with a keyword search for each value. Instead, you can use "
"field extraction to make Infinite Logging rules easier and more "
"manageable. First, create a log processing rule to extract a new field "
"called :guilabel:`status` from the portion of the field message that "
"contains the desired values. Then, create an Infinite Logging rule that "
"filters on :guilabel:`status` to include logs with the values , ‘START’, "
"‘RETRY’, ‘FAIL’, or ‘REPORT’."
msgstr ""

#: ../../logs/pipeline.rst:36
#, python-format
msgid ""
"Because Infinite Logging rules are last in the pipeline, log-derived "
"metrics are based on 100% of ingested logs, not on a sample of logs. "
"Thus, your organization can make use of full and accurate log-derived "
"metrics without needing to index all the logs that you metricize. For "
"example, say you want to create a metric to count the occurrences of "
"“puppies” or “kittens” in the message field, but you also want to archive"
" the logs containing those occurrences without indexing. First, create a "
"log processing rule to extract a new field called pet from the portion of"
" the message field that contains the desired values. Then, create a "
"metricization rule that records the count of all log messages, grouped by"
" pet. You can now graph or alert on the count of each pet from logs in "
"Observability Cloud dashboards and detectors. If you don’t want to see "
"the log messages in Log Observer, create an Infinite Logging rule that "
"archives without indexing all log messages that contain the field pet. "
"Now you have real-time visibility into logging trends without using index"
" capacity."
msgstr ""

#: ../../logs/pipeline.rst:39
msgid "Logs pipeline rules limits"
msgstr ""

#: ../../logs/pipeline.rst:40
msgid ""
"An organization can create a total of 128 log processing rules, which "
"includes the combined sum of field extraction rules, field copy rules, "
"and field redaction rules. In addition, an organization can create 128 "
"log metricization rules and 128 infinite logging rules."
msgstr ""

#: ../../logs/processors.rst:-1
msgid ""
"Manage the logs pipeline with log processing rules, log metricization "
"rules, and Infinite Logging rules. Customize your logs pipeline."
msgstr ""

#: ../../logs/processors.rst:5
msgid "Transform your data with log processing rules"
msgstr ""

#: ../../logs/processors.rst:10
msgid ""
"Only customers with a Splunk Log Observer entitlement in Splunk "
"Observability Cloud can create or manage log processing rules. If you do "
"not have a Log Observer entitlement and are using Splunk Log Observer "
"Connect instead, see :ref:`logs-intro-logconnect` to learn what you can "
"do with the Splunk Enterprise integration."
msgstr ""

#: ../../logs/processors.rst:12
msgid ""
"Add value to your raw logs by creating log processing rules, also known "
"as processors, to transform your data or a subset of your data as it "
"arrives."
msgstr ""

#: ../../logs/processors.rst:14
msgid ""
"To add more control to processors, you can add filters that determine "
"which logs a processor will be applied to."
msgstr ""

#: ../../logs/processors.rst:16
msgid ""
"On the Logs Pipeline Management page, you can adjust the order in which "
"your processing rules run, edit processors, or delete processors."
msgstr ""

#: ../../logs/processors.rst:18
msgid "You can't edit or delete prepackaged processors."
msgstr ""

#: ../../logs/processors.rst:20
msgid ""
"Prepackaged processors appear at the beginning of the list of processors,"
" and they're identified by a lock icon. These prepackaged processors "
"always execute before any processors you define. You can't modify or "
"reorder prepackaged processors."
msgstr ""

#: ../../logs/processors.rst:24
msgid ""
"One example of a prepackaged processor is the ``Level`` to ``severity`` "
"attributed remapper."
msgstr ""

#: ../../logs/processors.rst:26
msgid ""
"Splunk Observability Cloud includes prepackaged processors for Kubernetes"
" and Cassandra."
msgstr ""

#: ../../logs/processors.rst:29
msgid "Observability Cloud provides three types of log processors:"
msgstr ""

#: ../../logs/processors.rst:31
msgid ""
":ref:`Field extraction processors <field-extraction-processors>` create a"
" subset of log data by extracting fields and values."
msgstr ""

#: ../../logs/processors.rst:32
msgid ""
":ref:`Field copy processors <field-copy-processors>` create a set of log "
"data by moving field values from one field in the log record to a "
"different field name in a new record."
msgstr ""

#: ../../logs/processors.rst:34
msgid ""
":ref:`Field redaction processors <field-redaction-processors>` redact "
"data to mask personally identifiable information."
msgstr ""

#: ../../logs/processors.rst:46
msgid ""
"Because log processing rules execute first, you can create field "
"extraction rules, then use the resulting fields in log metricization "
"rules or infinite logging rules or both. For more information, see :ref"
":`logs-pipeline-sequence`."
msgstr ""

#: ../../logs/processors.rst:52
msgid "Field extraction processors"
msgstr ""

#: ../../logs/processors.rst:53
msgid ""
"Field extraction lets you find an existing field in your incoming logs "
"and create a processor based on the format of the field's value."
msgstr ""

#: ../../logs/processors.rst:56
msgid "Field extraction helps you do the following tasks:"
msgstr ""

#: ../../logs/processors.rst:58
msgid ""
"Filter logs based on the extracted fields. To learn more about filtering,"
" see :ref:`logs-keyword`."
msgstr ""

#: ../../logs/processors.rst:59
msgid ""
"Aggregate on extracted fields. To learn more, see :ref:`logs-"
"aggregations`."
msgstr ""

#: ../../logs/processors.rst:61
msgid "Consider the following raw log record"
msgstr ""

#: ../../logs/processors.rst:63
msgid ""
"`10.4.93.105 - - [04/Feb/2021:16:57:05 +0000] \"GET /metrics HTTP/1.1\" "
"200 73810 \"-\" \"Go-http-client/1.1\" 23`"
msgstr ""

#: ../../logs/processors.rst:65
msgid ""
"If you have not defined any processors in your logs pipeline, you can "
"only do a keyword search on the sample log, which searches the ``_raw`` "
"field. The following table shows how you can extract fields to define "
"processing rules:"
msgstr ""

#: ../../logs/processors.rst:72
msgid ":strong:`Example of value to extract`"
msgstr ""

#: ../../logs/processors.rst:73
msgid ":strong:`Processor definition to use`"
msgstr ""

#: ../../logs/processors.rst:75
msgid "IP address (10.4.93.105)"
msgstr ""

#: ../../logs/processors.rst:76
msgid "IP"
msgstr ""

#: ../../logs/processors.rst:78
msgid "04/Feb/2021:16:57:05 +0000"
msgstr ""

#: ../../logs/processors.rst:79
msgid "time"
msgstr ""

#: ../../logs/processors.rst:81
msgid "GET"
msgstr ""

#: ../../logs/processors.rst:82
msgid "method"
msgstr ""

#: ../../logs/processors.rst:84
msgid "/metrics"
msgstr ""

#: ../../logs/processors.rst:85
msgid "path"
msgstr ""

#: ../../logs/processors.rst:87
msgid ""
"Creating Regex and event time field extractions allows you to filter and "
"aggregate on the fields: IP, time, method, and path. This enables you to "
"create the query \"Display a Visual Analysis of the number of requests "
"from {IP} broken down by {method}\"."
msgstr ""

#: ../../logs/processors.rst:91
msgid ""
"Additionally, the extracted fields begin appearing in the fields summary "
"panel along with their top values and other statistics."
msgstr ""

#: ../../logs/processors.rst:94
msgid "There are three types of field extraction. These are:"
msgstr ""

#: ../../logs/processors.rst:96
msgid "Regex processors"
msgstr ""

#: ../../logs/processors.rst:97
msgid "JSON processors"
msgstr ""

#: ../../logs/processors.rst:98
msgid "Event time processors"
msgstr ""

#: ../../logs/processors.rst:99
msgid "KV parser processors"
msgstr ""

#: ../../logs/processors.rst:101
msgid "To start creating a field extraction, follow these steps:"
msgstr ""

#: ../../logs/processors.rst:103
msgid ""
"From the navigation menu, go to :guilabel:`Data Configuration > Logs "
"Pipeline Management`. A list of existing processors is displayed with the"
" prepackaged processors displaying first."
msgstr ""

#: ../../logs/processors.rst:106 ../../logs/processors.rst:203
#: ../../logs/processors.rst:227
msgid "Click :guilabel:`New Processing Rule`."
msgstr ""

#: ../../logs/processors.rst:108
msgid ""
"Alternatively, you can launch the processor wizard from Log Observer. To "
"do this, click into a log in the Logs table. The :guilabel:`Log Details` "
"panel appears on the right. Click a field value then select "
":menuselection:`Extract field`. This takes you to :guilabel:`Define "
"Processor`, the second step of the processor wizard. Skip to step 7."
msgstr ""

#: ../../logs/processors.rst:114
msgid ""
"Select :menuselection:`Field Extraction` as the processor type, then "
"click :guilabel:`Continue`. This takes you to :menuselection:`Select "
"sample`, the first step in the processor wizard."
msgstr ""

#: ../../logs/processors.rst:117
msgid ""
"To narrow your search for a log that contains the field you want to "
"extract, you can select a time from the time picker or click "
":guilabel:`Add Filter` and add keywords or fields."
msgstr ""

#: ../../logs/processors.rst:119 ../../logs/processors.rst:230
msgid ""
"Click the log containing the field you want. A list of fields and values "
"appears below the log line."
msgstr ""

#: ../../logs/processors.rst:122
msgid ""
"Click :guilabel:`Use as sample` next to the field you want to extract, "
"then click :guilabel:`Next`. This takes you to :guilabel:`Define "
"Processor`, the second step of the processor wizard."
msgstr ""

#: ../../logs/processors.rst:125
msgid "Select the extraction processor type that you want to use."
msgstr ""

#: ../../logs/processors.rst:127
msgid ""
"From here, follow the steps to create the extraction processor type you "
"selected:"
msgstr ""

#: ../../logs/processors.rst:129
msgid ":ref:`Regex processor <regex-processor>`"
msgstr ""

#: ../../logs/processors.rst:130
msgid ":ref:`JSON processor <json-processor>`"
msgstr ""

#: ../../logs/processors.rst:131
msgid ":ref:`Event time processor <event-time-processor>`"
msgstr ""

#: ../../logs/processors.rst:132
msgid ":ref:`KV parser processor<kv-processor>`"
msgstr ""

#: ../../logs/processors.rst:137
msgid "Create a Regex processor"
msgstr ""

#: ../../logs/processors.rst:138
msgid ""
"The regular expression workspace lets you to extract fields from your "
"data and then create a new processor using regex. Pipeline Management "
"makes suggestions to help you write the appropriate regex for your "
"processor. You can modify the regex within the processor wizard."
msgstr ""

#: ../../logs/processors.rst:143
msgid "To create a regex processor, follow these steps:"
msgstr ""

#: ../../logs/processors.rst:145
msgid ""
"Highlight the value of the field you want to extract in your sample and "
"select :menuselection:`Extract field` from the drop-down menu."
msgstr ""

#: ../../logs/processors.rst:146
msgid ""
"Click into the field name box and enter a name for the field you "
"selected. The default name is ``Field1``. Results display in a table."
msgstr ""

#: ../../logs/processors.rst:147
msgid ""
"Click `Edit regex` below the field name box if you want to modify the "
"regex that the processor has automatically generated to create this rule "
"based on your field name and value."
msgstr ""

#: ../../logs/processors.rst:148
msgid ""
"Preview your rule in the table to ensure that the correct fields are "
"extracted."
msgstr ""

#: ../../logs/processors.rst:149
msgid ""
"To apply your new rule to only a subset of incoming logs, add filters to "
"the content control bar. The new rule will apply only to logs matching "
"this filter."
msgstr ""

#: ../../logs/processors.rst:151
msgid ""
"In step 3 of the processor wizard entitled :guilabel:`Name, Save, and "
"Review`, give your new rule a name and description."
msgstr ""

#: ../../logs/processors.rst:152 ../../logs/processors.rst:178
#: ../../logs/processors.rst:235
msgid ""
"Review your configuration choices, then click :guilabel:`Save`. Your "
"processor defaults to :guilabel:`Active` and immediately begins "
"processing incoming logs."
msgstr ""

#: ../../logs/processors.rst:153 ../../logs/processors.rst:165
#: ../../logs/processors.rst:179 ../../logs/processors.rst:191
#: ../../logs/processors.rst:216 ../../logs/processors.rst:236
msgid ""
"To see your new processor, go to :guilabel:`Data Configuration > Logs "
"Pipeline Management`, expand the :guilabel:`Processing Rules` section, "
"and find it in the list. You can reorder, edit, or delete all processors "
"except those that are prepackaged (shown with a lock). To disable your "
"processor, click :guilabel:`Inactive`."
msgstr ""

#: ../../logs/processors.rst:158
msgid "Create a JSON processor"
msgstr ""

#: ../../logs/processors.rst:159
msgid "To create a JSON processor, follow these steps:"
msgstr ""

#: ../../logs/processors.rst:161
msgid ""
"To apply your new rule to only a subset of incoming logs, click "
":guilabel:`Add Filter` and add a keyword or field. The new rule will "
"apply only to logs matching this filter. Pipeline Management only applies"
" the new processor to log events that match this filter."
msgstr ""

#: ../../logs/processors.rst:162 ../../logs/processors.rst:188
msgid ""
"Preview your rule to ensure that Pipeline Management is extracting the "
"correct field values."
msgstr ""

#: ../../logs/processors.rst:163 ../../logs/processors.rst:189
msgid ""
"If you see the correct field values in the results table, click "
":guilabel:`Next`. Otherwise, adjust your filter."
msgstr ""

#: ../../logs/processors.rst:164 ../../logs/processors.rst:190
msgid ""
"Add a name and description for your new rule, then click "
":guilabel:`Save`. Your processor defaults to :guilabel:`Active` and "
"immediately begins processing incoming logs."
msgstr ""

#: ../../logs/processors.rst:170
msgid "Create an event time processor"
msgstr ""

#: ../../logs/processors.rst:171
msgid "To create an event time processor, follow these steps:"
msgstr ""

#: ../../logs/processors.rst:173
msgid ""
"Select a time format from the drop-down list. The wizard looks for the "
"selected format within your sample."
msgstr ""

#: ../../logs/processors.rst:174
msgid ""
"From the matches you see, select the time when the sample event occurred,"
" then click :guilabel:`Next`."
msgstr ""

#: ../../logs/processors.rst:175
msgid ""
"Add filters to the content control bar to define a matching condition, "
"then click :guilabel:`Next`. Pipeline Management only applies the new "
"processor to log events that match this filter."
msgstr ""

#: ../../logs/processors.rst:177 ../../logs/processors.rst:234
msgid "Give your new rule a name and description."
msgstr ""

#: ../../logs/processors.rst:184
msgid "Create a KV parser processor"
msgstr ""

#: ../../logs/processors.rst:185
msgid ""
"A KV parser processor is a rule that parses key-value (KV) pairs. To "
"create a KV parser processor, follow these steps:"
msgstr ""

#: ../../logs/processors.rst:187
msgid ""
"To apply your new rule to only a subset of incoming logs, click "
":guilabel:`Add Filter` then add a keyword or field. The new rule will "
"apply only to logs matching this filter."
msgstr ""

#: ../../logs/processors.rst:197
msgid "Field copy processors"
msgstr ""

#: ../../logs/processors.rst:198
msgid ""
"Field copy processors let you define a new relationship between new or "
"existing fields. One way to use Field Copy Processors is to use "
"OpenTelemetry mappings to help power your :ref:`Related Content <get-"
"started-relatedcontent>` suggestions."
msgstr ""

#: ../../logs/processors.rst:200
msgid "To create a field copy processor, follow these steps:"
msgstr ""

#: ../../logs/processors.rst:202 ../../logs/processors.rst:226
msgid ""
"From the navigation menu, go to :menuselection:`Data Configuration > Logs"
" Pipeline Management`."
msgstr ""

#: ../../logs/processors.rst:204
msgid "Select :menuselection:`Field Copy`, then click :guilabel:`Continue`."
msgstr ""

#: ../../logs/processors.rst:205
msgid ""
"Enter a target field in the first text box. You can choose from available"
" extracted fields in the drop-down list."
msgstr ""

#: ../../logs/processors.rst:207
msgid ""
"In the second text box, choose a field to which you want to map your "
"target field. The drop-down list options suggest OpenTelemetry mappings, "
"which help power your Related Content suggestions."
msgstr ""

#: ../../logs/processors.rst:210
msgid ""
"If you want to create multiple mappings, click :guilabel:`+ Add another "
"field copying rule` and repeat steps 4 and 5; otherwise, click "
":guilabel:`Next`."
msgstr ""

#: ../../logs/processors.rst:211
msgid ""
"To apply your new rule to only a subset of incoming logs, add filters to "
"the content control bar. The new rule is applied only to logs matching "
"this filter. If you do not add a filter, the rule is applied to all "
"incoming log events."
msgstr ""

#: ../../logs/processors.rst:214
msgid ""
"Preview your rule to ensure that Pipeline Management is extracting the "
"correct field values, then click :guilabel:`Next`."
msgstr ""

#: ../../logs/processors.rst:215
msgid ""
"Give your new rule a name and description, then click :guilabel:`Save`. "
"Your processor defaults to :guilabel:`Active` and immediately begins "
"processing incoming logs."
msgstr ""

#: ../../logs/processors.rst:222
msgid ""
"Field redaction lets you mask data, including personally identifiable "
"information."
msgstr ""

#: ../../logs/processors.rst:224
msgid "To create a field redaction processor, follow these steps:"
msgstr ""

#: ../../logs/processors.rst:228
msgid ""
"Select :menuselection:`Field Redaction`, then click :guilabel:`Continue`."
" This takes you to the first step in the processor wizard, Select "
":guilabel:`Sample`."
msgstr ""

#: ../../logs/processors.rst:229
msgid ""
"To find a log that contains the field you want to redact, add filters to "
"the content control bar until the Logs table displays a log with the "
"desired field."
msgstr ""

#: ../../logs/processors.rst:231
msgid ""
"Click :guilabel:`Use as sample` next to the field you want to redact, "
"then click :guilabel:`Next`. This takes you to :guilabel:`Define "
"Processor`, the second step of the processor wizard."
msgstr ""

#: ../../logs/processors.rst:232
msgid ""
"Select if you want to redact an entire field value or a partial field "
"value. If you want to redact a partial field value, highlight the portion"
" you want to redact. You can edit the regex here."
msgstr ""

#: ../../logs/processors.rst:233
msgid ""
"Define a matching condition. To apply your new rule to only a subset of "
"incoming logs, add filters to the content control bar. The new rule will "
"apply only to logs matching this filter."
msgstr ""

#: ../../logs/processors.rst:238
msgid ""
"If the field you redacted also appears in ``_raw``, it is still available"
" in ``_raw``. Redact the field in ``_raw`` in addition to redacting the "
"field itself."
msgstr ""

#: ../../logs/processors.rst:241
msgid "Log processing rules limits"
msgstr ""

#: ../../logs/processors.rst:242
msgid ""
"An organization can create a total of 128 log processing rules. The 128 "
"rule limit includes the combined sum of field extraction processors, "
"field copy processors, and field redaction processors."
msgstr ""

#: ../../logs/queries.rst:-1
msgid ""
"Overview of the various ways you can query logs in Log Observer. Browse, "
"search by keyword, filter, extract fields, or aggregate logs."
msgstr ""

#: ../../logs/queries.rst:5
msgid "Query logs in Log Observer"
msgstr ""

#: ../../logs/queries.rst:10
msgid ""
"You can search Splunk Observability Cloud logs if your Splunk "
"Observability Cloud instance ingests logs. Many Splunk platform (Splunk "
"Cloud Platform and Splunk Enterprise) users can access their Splunk "
"platform logs in Splunk Observability Cloud because their organization "
"has integrated its Splunk platform and Splunk Observability Cloud "
"instances. If you are using the integration, you can only access Splunk "
"platform logs in Splunk Observability Cloud if your Splunk platform role "
"has permissions to see that log's index in Splunk platform. Your Splunk "
"platform admin controls your permissions to see Splunk platform logs in "
"Splunk Observability Cloud."
msgstr ""

#: ../../logs/queries.rst:12
msgid ""
"Click any of the following documents to learn more about each way you can"
" explore, query, filter, and drill down into your logs:"
msgstr ""

#: ../../logs/queries.rst:23
msgid ""
"If your query might be useful in the future, save it, then return to it "
"in Saved Queries to run the query again. See :ref:`logs-save-share` to "
"learn how."
msgstr ""

#: ../../logs/raw-logs-display.rst:-1
msgid ""
"Browse logs in the logs table as they come into Log Observer or Log "
"Observer Connect. Customize the logs table display by field. See a count "
"of new log events."
msgstr ""

#: ../../logs/raw-logs-display.rst:5
msgid "Browse logs in the logs table"
msgstr ""

#: ../../logs/raw-logs-display.rst:10
msgid ""
"At the center of the Log Observer display is the logs table, which "
"displays log records as they come in. The most recent logs appear at the "
"beginning of the table. Scan the :guilabel:`Severity` to find important "
"severity levels, then click in the record line to see the record details."
msgstr ""

#: ../../logs/raw-logs-display.rst:15
msgid "These features help you browse the logs table:"
msgstr ""

#: ../../logs/raw-logs-display.rst:17
msgid ""
"Load log records by scrolling the table. As you scroll, you see records "
"for log events that occurred in the past. The logs table doesn't have a "
"scrolling limit, so you can scroll to see the oldest records."
msgstr ""

#: ../../logs/raw-logs-display.rst:19
msgid ""
"When new log records are available, a prompt displays the number of new "
"log events, such as :strong:`693 new events`. Click it to see the most "
"recent log results."
msgstr ""

#: ../../logs/raw-logs-display.rst:21
msgid ""
"You can now examine the currently displayed section of logs for as long "
"as you want."
msgstr ""

#: ../../logs/raw-logs-display.rst:23
msgid ""
"If you see important data in a log record, continue scrolling in the "
"table to find more occurrences. If you see repeated occurrences of log "
"records with an :guilabel:`ERROR` severity value, you might have a "
"problem in one of your systems."
msgstr ""

#: ../../logs/raw-logs-display.rst:25
msgid ""
"At the top top center of the logs table, find the button that displays "
"the number of events in the table. Click the button to refresh the table "
"and return to the current, incoming stream of logs."
msgstr ""

#: ../../logs/raw-logs-display.rst:28
msgid ""
"Sort the logs table by any column by clicking the title of that column or"
" the sort icon next to it."
msgstr ""

#: ../../logs/raw-logs-display.rst:30
msgid ""
"Display particular fields as column headers in the table by performing "
"the following steps:"
msgstr ""

#: ../../logs/raw-logs-display.rst:32
msgid ""
"In the logs table header row, click the :guilabel:`Configure Table` gear "
"icon."
msgstr ""

#: ../../logs/raw-logs-display.rst:34
msgid ""
"On the Table Settings popup, select the fields you want to display. You "
"can search for particular fields in the Search box. When finished, click "
":guilabel:`Apply Changes`. Each field you selected is now a column in the"
" table."
msgstr ""

#: ../../logs/raw-logs-display.rst:36
msgid ""
"You can customize the logs table display by adjusting the column width or"
" dragging and dropping columns to a new order."
msgstr ""

#: ../../logs/raw-logs-display.rst:39
msgid "Settings icon"
msgstr ""

#: ../../logs/save-share.rst:-1
msgid ""
"Collaborate with team members by sharing Log Observer or Log Observer "
"Connect queries. Saved queries include filters, aggregations, and search-"
"time rules."
msgstr ""

#: ../../logs/save-share.rst:5
msgid "Save and share Log Observer queries"
msgstr ""

#: ../../logs/save-share.rst:10
msgid ""
"Only customers with a Splunk Log Observer entitlement in Splunk "
"Observability Cloud can save and share Log Observer queries. If you do "
"not have a Log Observer entitlement and are using Splunk Log Observer "
"Connect instead, see :ref:`logs-intro-logconnect` to learn what you can "
"do with the Splunk Enterprise integration."
msgstr ""

#: ../../logs/save-share.rst:12
msgid ""
"After you create useful queries in Log Observer, you can save them and "
"share them with team members. You can only save or share queries on the "
":guilabel:`Observability Cloud data` index. A saved query is made up of a"
" filter and any aggregations or search-time rules you applied during the "
"search. You can only save a query if you have created a filter."
msgstr ""

#: ../../logs/save-share.rst:14
msgid ""
"To learn how to create filters, see :ref:`logs-keyword`. Log Observer "
"Connect has no default aggregation. Log Observer defaults to "
":guilabel:`All (*)`` logs grouped by :guilabel:`Severity`. To learn how "
"to create a unique aggregation, see :ref:`logs-aggregations`. To learn "
"how to create search-time rules, see :ref:`logs-search-time-rules`."
msgstr ""

#: ../../logs/save-share.rst:18
msgid ""
"All organizations have access to pre-defined queries for Kubernetes and "
"Cassandra. These queries appear at the beginning of the list of saved "
"queries and are a part of content packs. Content packs include pre-"
"defined saved queries as well as log processing rules. Splunk "
"Observability Cloud includes content packs for Kubernetes System Events "
"and Cassandra."
msgstr ""

#: ../../logs/save-share.rst:20
msgid ""
"You can also download the results of a query as a CSV or JSON file. See "
":ref:`exportCSV` to learn how."
msgstr ""

#: ../../logs/save-share.rst:24
msgid "Save a Log Observer query"
msgstr ""

#: ../../logs/save-share.rst:26
msgid "To create a query, follow these steps:"
msgstr ""

#: ../../logs/save-share.rst:28
msgid ""
"In the control bar, select the desired time increment from the time "
"picker, then in the :guilabel:`Index` field, select "
":guilabel:`Observability Cloud data`. Click :guilabel:`Add Filter`, then "
"enter a keyword or field."
msgstr ""

#: ../../logs/save-share.rst:30
msgid "To override the default aggregation, follow these steps:"
msgstr ""

#: ../../logs/save-share.rst:32
msgid ""
"Using the calculation control, set the calculation type you want from the"
" drop-down list. The default is :guilabel:`Count`."
msgstr ""

#: ../../logs/save-share.rst:33
msgid "Select the field that you want to aggregate by."
msgstr ""

#: ../../logs/save-share.rst:34
msgid ""
"In the :guilabel:`Group by` text box, type the name of the field you want"
" to group by."
msgstr ""

#: ../../logs/save-share.rst:35
msgid "Click :guilabel:`Apply`."
msgstr ""

#: ../../logs/save-share.rst:36
msgid ""
"Click the :guilabel:`Save` menu icon, then select :guilabel:`Save Query` "
"from the drop-down list. The Save Query dialog box appears."
msgstr ""

#: ../../logs/save-share.rst:38
msgid "In the :guilabel:`Name` text box, enter a name for your query."
msgstr ""

#: ../../logs/save-share.rst:39
msgid ""
"Optionally, you can describe the query in the :guilabel:`Description` "
"text box."
msgstr ""

#: ../../logs/save-share.rst:40
msgid ""
"Optionally, in the :guilabel:`Tags` text box, enter tags to help you and "
"your team locate the query. Log Observer stores tags you've used before "
"and auto-populates the :guilabel:`Tags` text box as you type."
msgstr ""

#: ../../logs/save-share.rst:42
msgid ""
"To save this query as a public query, click :guilabel:`Filter sharing "
"permissions set to public`. When you save a query as a public query, any "
"user in your organization can view and delete it in Log Observer."
msgstr ""

#: ../../logs/save-share.rst:47
msgid "Use Log Observer saved queries"
msgstr ""

#: ../../logs/save-share.rst:49
msgid ""
"You can view, share, set as default, or delete saved queries in the Saved"
" Queries catalog. To access the Saved Queries catalog, in the control bar"
" click :guilabel:`Saved Queries`."
msgstr ""

#: ../../logs/save-share.rst:52
msgid ""
"The following table lists the actions you can take in the Saved Queries "
"catalog."
msgstr ""

#: ../../logs/save-share.rst:58
msgid ":strong:`Desired action`"
msgstr ""

#: ../../logs/save-share.rst:59
msgid ":strong:`Procedure`"
msgstr ""

#: ../../logs/save-share.rst:61
msgid "Find a saved query"
msgstr ""

#: ../../logs/save-share.rst:62
msgid "Type the name or tags for a saved filter into the search box."
msgstr ""

#: ../../logs/save-share.rst:64
msgid "View or apply a saved query"
msgstr ""

#: ../../logs/save-share.rst:65
msgid "Click :guilabel:`Apply` to the right of the query you want to view."
msgstr ""

#: ../../logs/save-share.rst:67
msgid "Set a saved query as the default"
msgstr ""

#: ../../logs/save-share.rst:68
msgid ""
"Click the :guilabel:`More` icon for the query, then select "
":menuselection:`Make default query on page load`."
msgstr ""

#: ../../logs/save-share.rst:70
msgid "Change the current default saved query"
msgstr ""

#: ../../logs/save-share.rst:71
msgid ""
"Click the :guilabel:`More` icon for the query, then select "
":menuselection:`Unset as default query`, then click :guilabel:`Confirm`. "
"Next, set the new default query."
msgstr ""

#: ../../logs/save-share.rst:73
msgid "Delete a saved query from your Saved Queries catalog"
msgstr ""

#: ../../logs/save-share.rst:74
msgid ""
"Click the :guilabel:`More` icon for the query, then select "
":menuselection:`Delete Query`."
msgstr ""

#: ../../logs/save-share.rst:76
msgid ""
"If you set a saved query as default, Log Observer displays the result of "
"that query on launch."
msgstr ""

#: ../../logs/save-share.rst:82
msgid "Export query results as a CSV or JSON file"
msgstr ""

#: ../../logs/save-share.rst:84
msgid ""
"You can download a maximum of 10,000 logs at a time, even if your query "
"returned more than 10,000 logs."
msgstr ""

#: ../../logs/save-share.rst:86
msgid "To export query results, follow these steps:"
msgstr ""

#: ../../logs/save-share.rst:88
msgid "Click :strong:`Download` at the top of the Logs table."
msgstr ""

#: ../../logs/save-share.rst:90
msgid "Enter a name for your file."
msgstr ""

#: ../../logs/save-share.rst:92
msgid "Select :strong:`CSV` or :strong:`JSON`."
msgstr ""

#: ../../logs/save-share.rst:94
msgid "Click :strong:`Download`."
msgstr ""

#: ../../logs/scp.rst:-1
msgid ""
"Connect your Splunk Cloud Platform instance to Splunk Observability "
"Cloud. Set up Log Observer Connect to investigate logs in context with "
"metrics and traces."
msgstr ""

#: ../../logs/scp.rst:5
msgid "Set up Log Observer Connect for Splunk Cloud Platform"
msgstr ""

#: ../../logs/scp.rst:10
msgid ""
"Set up Log Observer Connect by integrating Log Observer with Splunk Cloud"
" Platform. If you are in a Splunk Enterprise environment and want to set "
"up Log Observer Connect, see :ref:`logs-set-up-logconnect`."
msgstr ""

#: ../../logs/scp.rst:12
msgid ""
"When you set up Log Observer Connect, your logs data remains strictly in "
"your Splunk Cloud Platform instance and is accessible only to Log "
"Observer Connect. Log Observer Connect does not store or index your logs "
"data. There is no additional charge for Log Observer Connect."
msgstr ""

#: ../../logs/scp.rst:16
msgid ""
"Splunk Log Observer Connect is available in the AWS regions us0, us1, "
"eu0, jp0, and au0. Log Observer Connect is not supported in GovCloud "
"regions. Splunk Log Observer Connect is compatible with Splunk Cloud "
"Platform versions 8.2 and higher. Log Observer Connect is not available "
"for Splunk Cloud Platform trials."
msgstr ""

#: ../../logs/scp.rst:18
msgid ""
"You can collect data using both the Splunk Distribution of OpenTelemetry "
"Collector and the universal forwarder without submitting any duplicate "
"telemetry data. See :ref:`collector-with-the-uf` to learn how."
msgstr ""

#: ../../logs/scp.rst:22
msgid ""
"Ensure that token authentication is enabled for your Log Observer Connect"
" service account in your Splunk Cloud Platform instance. See :new-"
"page:`Securing Splunk Cloud Platform: Enable or disable token "
"authentication token "
"<https://docs.splunk.com/Documentation/SplunkCloud/latest/Security/EnableTokenAuth>`"
" to learn how. The Splunk Cloud users you configure in the following "
"section must have the sc_admin role."
msgstr ""

#: ../../logs/scp.rst:26 ../../logs/set-up-logconnect.rst:42
msgid "Set up Log Observer Connect"
msgstr ""

#: ../../logs/scp.rst:27
msgid ""
"To set up Log Observer Connect for Splunk Cloud Platform without help "
"from the Support team, follow these steps:"
msgstr ""

#: ../../logs/scp.rst:30 ../../logs/set-up-logconnect.rst:47
msgid "Splunk Observability Cloud"
msgstr ""

#: ../../logs/scp.rst:31 ../../logs/set-up-logconnect.rst:48
msgid "In Splunk Observability Cloud, do the following:"
msgstr ""

#: ../../logs/scp.rst:33 ../../logs/set-up-logconnect.rst:50
msgid ""
"Go to :guilabel:`Settings > Log Observer Connect` and select "
":guilabel:`Add new connection`. If you don't see :guilabel:`Log Observer "
"Connect` in :guilabel:`Settings`, you are not an administrator in Splunk "
"Observability Cloud. Contact your organization's Splunk Observability "
"Cloud administrator to perform this integration."
msgstr ""

#: ../../logs/scp.rst:35
msgid "Select :guilabel:`Splunk Cloud Platform`."
msgstr ""

#: ../../logs/scp.rst:38
msgid "Splunk Cloud Platform"
msgstr ""

#: ../../logs/scp.rst:39
msgid ""
"In Splunk Cloud Platform, follow the instructions in the guided setup for"
" the integration to do the following:"
msgstr ""

#: ../../logs/scp.rst:41
msgid ""
"To configure a role in Splunk Cloud Platform for the Log Observer Connect"
" service account, go to :guilabel:`Settings > Roles`."
msgstr ""

#: ../../logs/scp.rst:43
msgid ""
"This screenshot shows how to go to Roles in Splunk Cloud Platform where "
"you will set up a service account for Log Observer Connect."
msgstr ""

#: ../../logs/scp.rst:47
msgid ""
"Select the role you want to use for the Log Observer Connect service "
"account. The service account is a user role that can access the specific "
"Splunk Cloud Platform indexes that you want your users to search in Log "
"Observer Connect."
msgstr ""

#: ../../logs/scp.rst:49 ../../logs/set-up-logconnect.rst:62
msgid ""
"On the :guilabel:`Capabilities` tab, ensure that ``edit_tokens_own`` is "
"selected. Also, ensure that ``indexes_list_all`` is not selected."
msgstr ""

#: ../../logs/scp.rst:51 ../../logs/set-up-logconnect.rst:64
msgid "This screenshot shows the Capabilities tab in user configuration."
msgstr ""

#: ../../logs/scp.rst:55 ../../logs/set-up-logconnect.rst:68
msgid ""
"On the :guilabel:`Indexes` tab in the :guilabel:`Included` column, "
"deselect :guilabel:`*(All internal indexes)` and select the indexes that "
"you want users to query in Log Observer Connect."
msgstr ""

#: ../../logs/scp.rst:57 ../../logs/set-up-logconnect.rst:70
msgid "This screenshot shows the Indexes tab in user configuration."
msgstr ""

#: ../../logs/scp.rst:61 ../../logs/set-up-logconnect.rst:74
msgid ""
"On the :guilabel:`Resources` tab, enter a :guilabel:`Standard search "
"limit` of 40 for both :guilabel:`Role search job limit` and "
":guilabel:`User search job limit`. Enter 0 for :guilabel:`Real-time "
"search limit` for both role and user search job limits."
msgstr ""

#: ../../logs/scp.rst:63 ../../logs/set-up-logconnect.rst:76
msgid ""
"The limit of 40 assumes that you have 10 Log Observer Connect users. To "
"determine your ideal :guilabel:`Standard search limit`, multiply the "
"number of Log Observer Connect users you have by 4. For example, if you "
"have 20 Log Observer users, enter a :guilabel:`Standard search limit` of "
"80 for both :guilabel:`Role search job limit` and :guilabel:`User search "
"job limit`."
msgstr ""

#: ../../logs/scp.rst:65 ../../logs/set-up-logconnect.rst:78
msgid ""
"This screenshot shows recommended configuration for role search job limit"
" and user search job limit."
msgstr ""

#: ../../logs/scp.rst:69 ../../logs/set-up-logconnect.rst:82
msgid ""
"Now, in the :guilabel:`Role search time window limit` section of the "
":guilabel:`Resources` tab, select :guilabel:`Custom time` and enter "
"2,592,000 seconds (30 days) for the maximum time window for searches for "
"this role. For the earliest searchable event time for this role,  select "
":guilabel:`Custom time` and enter 7,776,000 seconds (90 days). In the "
":guilabel:`Disk space limit` section enter a :guilabel:`Standard search "
"limit` of 1000 MB."
msgstr ""

#: ../../logs/scp.rst:71 ../../logs/set-up-logconnect.rst:84
msgid ""
"This screenshot shows recommended configuration for role search time "
"window limit and disk space limit."
msgstr ""

#: ../../logs/scp.rst:75
msgid ""
"Next, in Splunk Cloud Platform, go to :guilabel:`Settings > Users` and "
"create the user for the Log Observer Connect service account. In the "
":guilabel:`Assign roles` section, assign to the user the role you created"
" in the preceeding steps for the Log Observer Connect service account."
msgstr ""

#: ../../logs/scp.rst:77
msgid ""
"This screenshot shows the Create user page in Splunk Cloud Platform where"
" you can assign a user to the service account role."
msgstr ""

#: ../../logs/scp.rst:81
msgid ""
"Secure a connection to your Splunk Cloud Platform instance in Splunk "
"Observability Cloud. To get help from Splunk Support, :ref:`Submit a "
"support ticket <support-ticket>`. To do it yourself, open the third "
"section in the guided setup called :guilabel:`Secure connection to the "
"Splunk platform`. You can either select :guilabel:`Download this script` "
"and follow the instructions on screen, or you can copy the script from "
"the guided setup, then paste it into a shell script and run it. When you "
"run the script, the Admin Config Service API does the following:"
msgstr ""

#: ../../logs/scp.rst:83
msgid ""
"Adds Splunk Observability Cloud IPs and your local machine's IP to your "
"Splunk Cloud Platform allow list to allow Log Observer Connect services "
"and your machine to connect to your Splunk Cloud Platform instance "
"through the management port"
msgstr ""

#: ../../logs/scp.rst:85
msgid "Fetches a certificate chain"
msgstr ""

#: ../../logs/scp.rst:87
msgid "Removes your local machine's IP from the allow list"
msgstr ""

#: ../../logs/scp.rst:89
msgid ""
"Copy the first certificate in the chain and paste it on the next page of "
"the guided setup to securely connect Log Observer Connect and your Splunk"
" Cloud Platform instance. The script returns 3 certificates. Be sure to "
"copy only the first certificate and include ``-----BEGIN "
"CERTIFICATE-----`` and ``-----END CERTIFICATE-----``. The following is an"
" example of a certificate."
msgstr ""

#: ../../logs/scp.rst:91
msgid "``-----BEGIN CERTIFICATE-----``"
msgstr ""

#: ../../logs/scp.rst:93
msgid ""
"``MIIEiDCCA3CgAwIBAgIQYtRkQZS4gkQSqEN/3NaYgjANBgkqhkiG9w0BAQsFADBG "
"MQswCQYDVQQGEwJVUzEiMCAGA1UEChMZR29vZ2xlIFRydXN0IFNlcnZpY2VzIExM "
"QzETMBEGA1UEAxMKR1RTIENBIDFDMzAeFw0yMzAyMjAwOTE1MzRaFw0yMzA1MTUw "
"OTE1MzNaMBkxFzAVBgNVBAMTDnd3dy5nb29nbGUuY29tMFkwEwYHKoZIzj0CAQYI "
"KoZIzj0DAQcDQgAEOU31sc6basWKjNmWj0gWF9ewzDavJK3QKASkQ/V7XwatprPh "
"/vnuEzWx8vYY1Rlfcy5Yhsxpa/Cb9Iomn+wIaqOCAmgwggJkMA4GA1UdDwEB/wQE "
"AwIHgDATBgNVHSUEDDAKBggrBgEFBQcDATAMBgNVHRMBAf8EAjAAMB0GA1UdDgQW "
"BBQilv+CDxMpP/SuW5VTeT4rzLTAoTAfBgNVHSMEGDAWgBSKdH+vhc3ulc09nNDi "
"RhTzcTUdJzBqBggrBgEFBQcBAQReMFwwJwYIKwYBBQUHMAGGG2h0dHA6Ly9vY3Nw "
"LnBraS5nb29nL2d0czFjMzAxBggrBgEFBQcwAoYlaHR0cDovL3BraS5nb29nL3Jl "
"cG8vY2VydHMvZ3RzMWMzLmRlcjAZBgNVHREEEjAQgg53d3cuZ29vZ2xlLmNvbTAh "
"BgNVHSAEGjAYMAgGBmeBDAECATAMBgorBgEEAdZ5AgUDMDwGA1UdHwQ1MDMwMaAv "
"oC2GK2h0dHA6Ly9jcmxzLnBraS5nb29nL2d0czFjMy9tb1ZEZklTaWEyay5jcmww "
"ggEFBgorBgEEAdZ5AgQCBIH2BIHzAPEAdwCt9776fP8QyIudPZwePhhqtGcpXc+x "
"DCTKhYY069yCigAAAYZuUlZbAAAEAwBIMEYCIQDlwIgI7EnPSD21IsDsf1botxy/ "
"Blfi2jKy60WpGq+XNgIhAI8L2XYzQ8OEGsw7JmpWC/hOKSB18n6wqB3EMWYFoaRc "
"AHYAejKMVNi3LbYg6jjgUh7phBZwMhOFTTvSK8E6V6NS61IAAAGGblJWVQAABAMA "
"RzBFAiBd+rIH4lPny35N5OmGqOEYNXl3rK7pfzfjZH0sFF30TwIhAKK4pgWZO0IN "
"fTzqnyWKEbmqy6lyNvl/khtYreqsvE0eMA0GCSqGSIb3DQEBCwUAA4IBAQCyw1us "
"+cEBWh7HglwAoU1TMStbdNrugviDQ3DoBnGL4N+sCjOfXzCXGhINLwzv8KfAZV+Y "
"0IX4nGNyliDu7Gd6vt+pnyLUsI2fTfPZq6Po14rNGaC8vRHcN+Yo317ylo6sQD6E "
"Z04CmlIA4JUzEtj1H6tj69RjyxDqV5EXsGLJ+DIJ4JYAm5xi6gEvFkdhnVYvHV5W "
"0BNRR+EO4Vw/tOkpyisemMt9L9aFZ4HaEuiSvL3R/HGU94uCxXc+TFwmVTelVFZN "
"eP4Q0ck4ooUOd7XgCc5qdvCiCiD/268+gBNSHhJSPZXeuzC6vL7mMKVY4I80sKKP "
"F+4goIJZUyLdHZ+a``"
msgstr ""

#: ../../logs/scp.rst:119
msgid "``-----END CERTIFICATE-----``"
msgstr ""

#: ../../logs/scp.rst:121 ../../logs/set-up-logconnect.rst:96
msgid ""
"Make sure to give each connection a unique name on the final page of the "
"Log Observer Connect guided setup."
msgstr ""

#: ../../logs/scp.rst:123
msgid ""
"Manage concurrent search limits using your current strategy in Splunk "
"Cloud Platform. All searches initiated by Log Observer Connect users go "
"through the service account you create in Splunk Cloud Platform. For each"
" active Log Observer Connect user, four back-end searches occur when a "
"user performs a search in Log Observer Connect. For example, if there are"
" three users accessing Log Observer Connect at the same time, the service"
" account for Log Observer Connect initiates approximately 12 searches in "
"Splunk Cloud Platform."
msgstr ""

#: ../../logs/scp.rst:128
msgid "Submit a support ticket"
msgstr ""

#: ../../logs/scp.rst:129
msgid ""
"If you were not able to run the script in step 3d in the preceeding "
"section, you may submit a support ticket from your Splunk Cloud Platform "
"instance to do this on your behalf. Submit a ticket to Splunk Support to "
"configure your Splunk Cloud Platform instance’s IP allow list. "
"Configuring your allow list properly opens your Splunk Cloud Platform "
"instance management port to Log Observer Connect, which can then search "
"your Splunk Cloud Platform instance log data. After Splunk Support "
"prepares your Splunk Cloud Platform instance, you can securely create a "
"connection to Log Observer Connect."
msgstr ""

#: ../../logs/scp.rst:131
msgid "To submit a support ticket, follow these steps:"
msgstr ""

#: ../../logs/scp.rst:133
msgid "Find the following:"
msgstr ""

#: ../../logs/scp.rst:135
msgid ""
"Your Splunk Observability Cloud organization name and region. To see this"
" information in Splunk Observability Cloud, go to :guilabel:`Settings`, "
"then select your profile name."
msgstr ""

#: ../../logs/scp.rst:137
msgid ""
"Your Splunk Cloud Platform instance name, the URL prefix of your Splunk "
"Cloud Platform deployment, which is formatted as such: "
"[Your_instance_name].splunkcloud.com."
msgstr ""

#: ../../logs/scp.rst:139
msgid ""
"Log in to your Splunk Cloud Platform instance and select "
":guilabel:`Support`."
msgstr ""

#: ../../logs/scp.rst:141
msgid ""
"Select :guilabel:`Support Portal` from the drop-down list to submit a "
"case ticket."
msgstr ""

#: ../../logs/scp.rst:143
msgid ""
"In the description of your ticket, paste the following and enter the "
"relevant values for your organization:"
msgstr ""

#: ../../logs/scp.rst:153
msgid ""
"When you receive the SSL certificate from Splunk Support in your support "
"ticket, do the following:"
msgstr ""

#: ../../logs/scp.rst:155
msgid ""
"Paste the first certificate stanza in the final section of the Log "
"Observer Connect guided setup, :guilabel:`Set up Observability Cloud`."
msgstr ""

#: ../../logs/scp.rst:157
msgid "Select :guilabel:`Save and Activate`."
msgstr ""

#: ../../logs/scp.rst:161 ../../logs/set-up-logconnect.rst:101
msgid "Troubleshooting"
msgstr ""

#: ../../logs/scp.rst:162
msgid ""
"See :ref:`logs-LOconnect-troubleshoot` to learn how to solve common "
"issues with Log Observer Connect."
msgstr ""

#: ../../logs/search-time-rules.rst:-1
msgid ""
"Transform your data with a log processing rule, then apply the rule to "
"logs that came in before the rule existed. Learn about search-time vs. "
"index-time rules."
msgstr ""

#: ../../logs/search-time-rules.rst:5
msgid "Apply processing rules across historical data"
msgstr ""

#: ../../logs/search-time-rules.rst:10
msgid ""
"Only customers with a Splunk Log Observer entitlement in Splunk "
"Observability Cloud can apply processing rules across historical data. If"
" you do not have a Log Observer entitlement and are using Splunk Log "
"Observer Connect instead, see :ref:`logs-intro-logconnect` to learn what "
"you can do with the Splunk Enterprise integration."
msgstr ""

#: ../../logs/search-time-rules.rst:13
msgid "What are search-time rules?"
msgstr ""

#: ../../logs/search-time-rules.rst:15
msgid ""
"Search-time rules are the application of log processing rules across "
"historical data. Log processing rules can occur at index time or at "
"search time. Index-time rules can only be applied to data that streams in"
" after the index-time rule was created. To learn more about index-time "
"rules, see :ref:`logs-processors`. It can be helpful to apply an index-"
"time rule to data that streamed in before the index-time rule existed. To"
" do so, create a search-time rule."
msgstr ""

#: ../../logs/search-time-rules.rst:17
msgid "The following table compares search-time rules and index-time rules."
msgstr ""

#: ../../logs/search-time-rules.rst:23
msgid ":strong:`Search-time rule`"
msgstr ""

#: ../../logs/search-time-rules.rst:24
msgid ":strong:`Index-time rule`"
msgstr ""

#: ../../logs/search-time-rules.rst:26 ../../logs/search-time-rules.rst:27
msgid "Transforms your data or a subset of your data"
msgstr ""

#: ../../logs/search-time-rules.rst:29
msgid "Apply to data from any time period"
msgstr ""

#: ../../logs/search-time-rules.rst:30
msgid ""
"Apply only to data that streamed in after the rule was created and "
"activated"
msgstr ""

#: ../../logs/search-time-rules.rst:32
msgid "Is part of a query"
msgstr ""

#: ../../logs/search-time-rules.rst:33
msgid "Is part of the logs pipeline"
msgstr ""

#: ../../logs/search-time-rules.rst:35
msgid ""
"Activate or deactivate in :guilabel:`Saved Queries` or :guilabel:`Active "
"search-time rules` in Log Observer"
msgstr ""

#: ../../logs/search-time-rules.rst:36
msgid ""
"Activate or deactivate in :guilabel:`Data Configuration > Logs Pipeline "
"Management`"
msgstr ""

#: ../../logs/search-time-rules.rst:39
msgid ""
"Do not activate search-time rules except when you are intentionally "
"applying index-time rules to historical data. Applying search-time rules "
"does not impact the subscription usage, but does impact performance. "
"Search-time rules are transformations that increase the time it takes to "
"complete a search. Applying index-time rules can impact index "
"subscription usage, but does not impact performance."
msgstr ""

#: ../../logs/search-time-rules.rst:43
msgid "Use case for applying search-time rules"
msgstr ""

#: ../../logs/search-time-rules.rst:45
msgid ""
"You can apply search-time rules when you discover a problem after the "
"fact. For example, suppose an error occurred between 2 am and 5 am last "
"night and no one was on duty to track down the cause. This morning at 9 "
"am, you discover the error occurred and try to figure out what went "
"wrong. You create field extractions to define a few fields to make "
"filtering easier. The new fields, which were created with index-time "
"rules, can only be applied to logs that stream in after you created the "
"fields at 9 am. To apply your newly created fields to logs that streamed "
"in between 2 am and 5 am, create a search-time rule based on the index-"
"time rule you created at 9 am, then activate it as a search-time rule and"
" apply it to logs that came in between 2 am and 5 am."
msgstr ""

#: ../../logs/search-time-rules.rst:49
msgid "Create and activate a search-time rule"
msgstr ""

#: ../../logs/search-time-rules.rst:51
msgid "To create a search-time rule, follow these steps:"
msgstr ""

#: ../../logs/search-time-rules.rst:53
msgid ""
"Create an index-time rule from an individual log or in Logs Pipeline "
"Management. See the :guilabel:`Field extraction processors` section of "
":ref:`logs-processors` to learn how. :guilabel:`Note`: You can apply only"
" Regex processing rules at search time."
msgstr ""

#: ../../logs/search-time-rules.rst:54
msgid ""
"Click :guilabel:`Active Search-time rules` in Log Observer. A :guilabel"
":`Search-time rules` panel appears."
msgstr ""

#: ../../logs/search-time-rules.rst:55
msgid ""
"On the :guilabel:`Search-time rules` panel, click the :guilabel:`Index-"
"time rules` tab."
msgstr ""

#: ../../logs/search-time-rules.rst:56
msgid ""
"Find and select your index-time rule in the list to activate it at search"
" time, then click :guilabel:`Apply 1 rule at search time`."
msgstr ""

#: ../../logs/search-time-rules.rst:57
msgid "Click the :guilabel:`Search-time rules` tab."
msgstr ""

#: ../../logs/search-time-rules.rst:58
msgid ""
"Drag the active search-time rules to obtain the order in which you want "
"to apply the rules."
msgstr ""

#: ../../logs/search-time-rules.rst:59
msgid ""
"Adjust the time in the Log Observer time picker to apply the rule to the "
"historical data you want."
msgstr ""

#: ../../logs/search-time-rules.rst:63
msgid "Deactivate a search-time rule"
msgstr ""

#: ../../logs/search-time-rules.rst:65
msgid "To deactivate a search-time rule, follow these steps:"
msgstr ""

#: ../../logs/search-time-rules.rst:67
msgid "In Log Observer, click :guilabel:`Active search-time rules`."
msgstr ""

#: ../../logs/search-time-rules.rst:68
msgid ""
"On the :guilabel:`Search-time rules` panel, click the :guilabel:`Active "
"search-time rules` tab."
msgstr ""

#: ../../logs/search-time-rules.rst:69
msgid ""
"Find and select the rule you want to deactivate, then click "
":guilabel:`Deactivate 1 rule`."
msgstr ""

#: ../../logs/search-time-rules.rst:73
msgid "Save a search-time rule"
msgstr ""

#: ../../logs/search-time-rules.rst:75
msgid ""
"When you create a search-time rule, it automatically becomes part of the "
"current query. To save the rule, save the query. See :ref:`logs-save-"
"share` to learn how."
msgstr ""

#: ../../logs/set-up-logconnect.rst:-1
msgid ""
"Connect your Splunk Enterprise instance to Splunk Observability Cloud. "
"Set up Log Observer Connect to investigate logs in context with metrics "
"and traces."
msgstr ""

#: ../../logs/set-up-logconnect.rst:5
msgid "Set up Log Observer Connect for Splunk Enterprise"
msgstr ""

#: ../../logs/set-up-logconnect.rst:10
msgid ""
"Set up Log Observer Connect by integrating Log Observer with Splunk "
"Enterprise. If you are in a Splunk Cloud Platform environment and want to"
" set up Log Observer Connect, see :ref:`logs-scp`."
msgstr ""

#: ../../logs/set-up-logconnect.rst:12
msgid ""
"When you set up Log Observer Connect, your Splunk Enterprise logs data "
"remains in Splunk Enterprise. Log Observer Connect does not store or "
"index your logs data. There is no additional charge for Log Observer "
"Connect."
msgstr ""

#: ../../logs/set-up-logconnect.rst:15
msgid "Region and version compatibility"
msgstr ""

#: ../../logs/set-up-logconnect.rst:17
msgid ""
"Splunk Log Observer Connect is available in the AWS regions us0, us1, "
"eu0, jp0, and au0. Splunk Log Observer Connect is compatible with Splunk "
"Enterprise 8.2 and higher."
msgstr ""

#: ../../logs/set-up-logconnect.rst:24
msgid "Ensure the following configuration in your Splunk Enterprise instance:"
msgstr ""

#: ../../logs/set-up-logconnect.rst:26
msgid ""
"Token authentication is active on your Log Observer Connect service "
"account. See :new-page:`Securing Splunk Enterprise: Enable or disable "
"token authentication "
"<https://docs.splunk.com/Documentation/Splunk/latest/Security/EnableTokenAuth>`"
" to learn how."
msgstr ""

#: ../../logs/set-up-logconnect.rst:28
msgid "Allow these IPs:"
msgstr ""

#: ../../logs/set-up-logconnect.rst:30
msgid ""
"us0: ``34.199.200.84``, ``52.20.177.252``, ``52.201.67.203``, "
"``54.89.1.85``"
msgstr ""

#: ../../logs/set-up-logconnect.rst:31
msgid ""
"us1: ``44.230.152.35``, ``44.231.27.66``, ``44.225.234.52``, "
"``44.230.82.104``"
msgstr ""

#: ../../logs/set-up-logconnect.rst:32
msgid "eu0: ``108.128.26.145``, ``34.250.243.212``, ``54.171.237.247``"
msgstr ""

#: ../../logs/set-up-logconnect.rst:33
msgid "jp0: ``35.78.47.79``, ``35.77.252.198``, ``35.75.200.181``"
msgstr ""

#: ../../logs/set-up-logconnect.rst:34
msgid "au0: ``13.54.193.47``, ``13.55.9.109``, ``54.153.190.59``"
msgstr ""

#: ../../logs/set-up-logconnect.rst:36
msgid "Expose port ``8089`` to all the IPs of the realms you're using."
msgstr ""

#: ../../logs/set-up-logconnect.rst:39
msgid ""
"Check with your security team before you add these IPs to the allow list "
"of your firewall rules or to your security groups in AWS."
msgstr ""

#: ../../logs/set-up-logconnect.rst:44
msgid "To set up Log Observer Connect for Splunk Enterprise, follow these steps:"
msgstr ""

#: ../../logs/set-up-logconnect.rst:52
msgid "Select :guilabel:`Splunk Enterprise`."
msgstr ""

#: ../../logs/set-up-logconnect.rst:55
msgid "Splunk Enterprise"
msgstr ""

#: ../../logs/set-up-logconnect.rst:56
msgid ""
"In Splunk Enterprise, follow the instructions in the guided setup for the"
" integration to do the following:"
msgstr ""

#: ../../logs/set-up-logconnect.rst:58
msgid ""
"To configure a role in Splunk Enterprise for the Log Observer Connect "
"service account, go to :guilabel:`Settings > Roles`."
msgstr ""

#: ../../logs/set-up-logconnect.rst:60
msgid ""
"Select the role you want to use for the Log Observer Connect service "
"account. The service account is a user role that can access the specific "
"Splunk Enterprise indexes that you want your users to search in Log "
"Observer Connect."
msgstr ""

#: ../../logs/set-up-logconnect.rst:88
msgid ""
"Next, in Splunk Enterprise, go to :guilabel:`Settings > Users` and create"
" the user for the Log Observer Connect service account. In the "
":guilabel:`Assign roles` section, assign to the user the role you created"
" in the preceeding steps for the Log Observer Connect service account."
msgstr ""

#: ../../logs/set-up-logconnect.rst:90
msgid ""
"This screenshot shows the Create user page in Splunk Enterprise where you"
" can assign a user to the service account role."
msgstr ""

#: ../../logs/set-up-logconnect.rst:94
msgid ""
"Obtain certificates for securing inter-Splunk communication. See :new-"
"page:`Configure and install certificates in Splunk Enterprise for Splunk "
"Log Observer Connect "
"<https://quickdraw.splunk.com/redirect/?product=Observability&location=splunk.integration.third.party&version=current>`"
" to learn how. Copy only the first certificate in the chain and paste it "
"on the next page of the guided setup to securely connect Log Observer "
"Connect and your Splunk Enterprise instance."
msgstr ""

#: ../../logs/set-up-logconnect.rst:98
msgid ""
"Manage concurrent search limits using your current strategy in Splunk "
"Enterprise. All searches initiated by Log Observer Connect users go "
"through the service account you create in Splunk Enterprise. For each "
"active Log Observer Connect user, four back-end searches occur when a "
"user performs a search in the Log Observer Connect UI. For example, if "
"there are three concurrent users accessing the Log Observer Connect UI at"
" the same time, the service account for Log Observer Connect initiates "
"approximately 12 searches in Splunk Enterprise."
msgstr ""

#: ../../logs/set-up-logconnect.rst:102
msgid ""
"See :ref:`logs-LOconnect-troubleshoot` to learn how to solve common  "
"issues with Log Observer Connect."
msgstr ""

#: ../../logs/timeline.rst:-1
msgid ""
"Log Observer Timeline displays a histogram chart of logged events over "
"time, grouped by values of the “message” field. See the spread of error "
"severity levels."
msgstr ""

#: ../../logs/timeline.rst:5
msgid "View overall system health using Timeline"
msgstr ""

#: ../../logs/timeline.rst:10
msgid ""
"The Log Observer Timeline displays a histogram of logged events over "
"time, grouped by values of the message field ``severity``. Note that Log "
"Observer Connect has no default aggregation. You can change Log "
"Observer's default aggregation by changing the value in the "
":strong:`Group by` field. To learn more, see :new-page-ref:`logs-"
"aggregations`."
msgstr ""

#: ../../logs/timeline.rst:12
msgid ""
"These features help you use the Timeline to review the health of your "
"systems:"
msgstr ""

#: ../../logs/timeline.rst:14
msgid "Review the histogram to see the spread of error severity levels."
msgstr ""

#: ../../logs/timeline.rst:16
msgid ""
"The histogram displays severity values in time intervals (histogram "
"buckets). The logs processor service extracts these severity values from "
"the incoming data. Each histogram interval shows a stacked column of "
"severity values, and each value has a unique color. To identify each "
"value in a column by color, use the Timeline legend."
msgstr ""

#: ../../logs/timeline.rst:20
msgid "Adjust the time picker in the top left."
msgstr ""

#: ../../logs/timeline.rst:22
msgid "To adjust the duration of each histogram bucket, use the time picker."
msgstr ""

#: ../../logs/timeline.rst:24
msgid ""
"The Live Tail option doesn't display a histogram. Use filtering or "
"keyword highlighting to review incoming log records. To learn more, see "
":new-page-ref:`logs-live-tail`."
msgstr ""

#: ../../logs/timeline.rst:26
msgid ""
"Other options display histograms over a previous time period. Log "
"Observer calculates the time intervals for each histogram bucket. The "
"duration of each interval appears in the control bar."
msgstr ""

#: ../../logs/timeline.rst:28
msgid ""
"To display a histogram for a specific time period, use the "
":menuselection:`Custom Time` option."
msgstr ""

#: ../../logs/timeline.rst:29
msgid ""
"By default, the time period for the histogram is :menuselection:`Last 5 "
"minutes`, which displays buckets for the last 5 minutes of log data. In "
"the preceding example, there are 10,306 log events, and the time interval"
" for the histogram buckets is 10 seconds."
msgstr ""

#: ../../logs/timeline.rst:33
msgid ""
"Highlight buckets in the Timeline to narrow the time period. Log Observer"
" drills down into the portion you highlight, and the histogram shows "
"results in the new time period. To highlight buckets, do the following:"
msgstr ""

#: ../../logs/timeline.rst:36
msgid ""
"Click anywhere in the Timeline and drag to surround the time interval on "
"which you want to zoom in."
msgstr ""

#: ../../logs/timeline.rst:38
msgid ""
"To accept your selection, click :guilabel:`Filter to selection`. Log "
"Observer recalculates the time period and the histogram buckets and "
"displays the result."
msgstr ""

#: ../../logs/timestamp.rst:-1
msgid ""
"Log Observer determines a log’s time and assigns it to _time. Time comes "
"from event time processor, HEC protocol timestamp, or entrance into "
"Observability Cloud."
msgstr ""

#: ../../logs/timestamp.rst:5
msgid "Where does a log’s logical time come from?"
msgstr ""

#: ../../logs/timestamp.rst:10
msgid ""
"A log’s logical time can come from different places, depending on what "
"data is available for the log. Your logs may have fields, such as "
"``timestamp`` or ``Time``, that sound like the log’s logical time. "
"However, Log Observer determines the log’s logical time and assigns it to"
" the field, ``_time``. If your logs already contain the field ``_time``, "
"Log Observer overwrites it."
msgstr ""

#: ../../logs/timestamp.rst:12
msgid ""
"Log Observer applies the following three rules, in priority order, to "
"determine each log’s logical time:"
msgstr ""

#: ../../logs/timestamp.rst:14
msgid ""
"The time matched and parsed by any rule you created using an event time "
"processor, a log processing rule (See :ref:`event-time-processor` for "
"more information.)"
msgstr ""

#: ../../logs/timestamp.rst:15
msgid ""
"The timestamp sent as part of the HTTP Event Collector (HEC) protocol as "
"the event time"
msgstr ""

#: ../../logs/timestamp.rst:16
msgid "The time when the log event hits Splunk Observability Cloud"
msgstr ""

#: ../../logs/timestamp.rst:18
msgid ""
"First, Log Observer checks for a matching event time processor, rule 1 in"
" the preceding list. If there is a match, it is used as the logical time."
" Log Observer prioritizes an event time processor rule first because it "
"was a rule you created to determine your logs’ logical time."
msgstr ""

#: ../../logs/timestamp.rst:20
msgid ""
"If there is no match to an event time processor rule, Log Observer checks"
" for a timestamp sent as part of the HEC protocol as the event time. If "
"there is a HEC protocol timestamp, it becomes that log’s logical time in "
"Log Observer."
msgstr ""

#: ../../logs/timestamp.rst:22
msgid ""
"If there is no HEC protocol timestamp, Log Observer uses the time when "
"the log event first hits Splunk Observability Cloud as the log’s logical "
"time."
msgstr ""

